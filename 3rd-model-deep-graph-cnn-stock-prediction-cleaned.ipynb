{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd Model: Deepgraph CNN: Stock Price Prediction using DeepGraphCNN Neural Networks. It includes GCN layers and CNN layers. I have added an MLP at the last layer to predict stock prices.\n",
    "\n",
    "# Input graphs were created for Pearson, Spearman, and Kendal Tau correlations/coefficients from historical stock prices. Also, another graph is created based on financial news articles.\n",
    "\n",
    "# For the sake of making execution easier (and at once), I have kept multiple approaches (Pearson, Spearman, and Kendal Tau, News Based) in the same file. One big code file can be difficult to handle; is done just for making execution easier.\n",
    "\n",
    "# Because I initially tried separately and brought the code together, some code might be a bit redundant/repeating. I may have done some cleaning.\n",
    "\n",
    "# An use case of DeepGraphCNN for Node Classification\n",
    "# https://stellargraph.readthedocs.io/en/latest/demos/graph-classification/dgcnn-graph-classification.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jiTeJ1lXcfkc"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries for Graph, GNN, and GCN\n",
    "import stellargraph as sg\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.layer import DeepGraphCNN\n",
    "from stellargraph.mapper import FullBatchNodeGenerator\n",
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "from stellargraph.layer import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learnig related library Imports\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
    "from sklearn import preprocessing, model_selection\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to drop NAN column or row wise for stock price data\n",
    "# I did not need to use this options that much\n",
    "drop_cols_with_na = 1\n",
    "drop_rows_with_na = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: Using 30 companies from the Fortune 500 companies (the paper used these stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>ANTM</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>CAH</th>\n",
       "      <th>COST</th>\n",
       "      <th>CVS</th>\n",
       "      <th>...</th>\n",
       "      <th>PCAR</th>\n",
       "      <th>PSX</th>\n",
       "      <th>T</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03 00:00:00</td>\n",
       "      <td>29.037500</td>\n",
       "      <td>82.610001</td>\n",
       "      <td>37.683498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.970001</td>\n",
       "      <td>22.530001</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>159.729996</td>\n",
       "      <td>80.349998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.546665</td>\n",
       "      <td>86.790001</td>\n",
       "      <td>32.492447</td>\n",
       "      <td>161.449997</td>\n",
       "      <td>102.519997</td>\n",
       "      <td>54.580002</td>\n",
       "      <td>82.959999</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>68.660004</td>\n",
       "      <td>90.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04 00:00:00</td>\n",
       "      <td>29.004999</td>\n",
       "      <td>84.660004</td>\n",
       "      <td>37.859001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.619995</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>75.629997</td>\n",
       "      <td>159.759995</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.146667</td>\n",
       "      <td>87.260002</td>\n",
       "      <td>32.303623</td>\n",
       "      <td>161.910004</td>\n",
       "      <td>103.139999</td>\n",
       "      <td>54.520000</td>\n",
       "      <td>82.980003</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>69.059998</td>\n",
       "      <td>89.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05 00:00:00</td>\n",
       "      <td>29.152500</td>\n",
       "      <td>83.680000</td>\n",
       "      <td>39.022499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.710007</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>162.910004</td>\n",
       "      <td>81.419998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.426666</td>\n",
       "      <td>86.739998</td>\n",
       "      <td>32.212990</td>\n",
       "      <td>162.179993</td>\n",
       "      <td>102.129997</td>\n",
       "      <td>54.639999</td>\n",
       "      <td>83.029999</td>\n",
       "      <td>55.180000</td>\n",
       "      <td>69.209999</td>\n",
       "      <td>88.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06 00:00:00</td>\n",
       "      <td>29.477501</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>39.799500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.100006</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>75.330002</td>\n",
       "      <td>162.830002</td>\n",
       "      <td>82.199997</td>\n",
       "      <td>...</td>\n",
       "      <td>43.919998</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>31.208460</td>\n",
       "      <td>162.410004</td>\n",
       "      <td>103.190002</td>\n",
       "      <td>53.259998</td>\n",
       "      <td>83.099998</td>\n",
       "      <td>55.040001</td>\n",
       "      <td>68.260002</td>\n",
       "      <td>88.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09 00:00:00</td>\n",
       "      <td>29.747499</td>\n",
       "      <td>85.480003</td>\n",
       "      <td>39.846001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.320007</td>\n",
       "      <td>22.549999</td>\n",
       "      <td>74.760002</td>\n",
       "      <td>160.970001</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>84.019997</td>\n",
       "      <td>30.815710</td>\n",
       "      <td>161.949997</td>\n",
       "      <td>102.419998</td>\n",
       "      <td>52.680000</td>\n",
       "      <td>82.550003</td>\n",
       "      <td>54.240002</td>\n",
       "      <td>68.709999</td>\n",
       "      <td>87.040001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date       AAPL        ABC       AMZN  ANTM          BA  \\\n",
       "0  2017-01-03 00:00:00  29.037500  82.610001  37.683498   NaN  156.970001   \n",
       "1  2017-01-04 00:00:00  29.004999  84.660004  37.859001   NaN  158.619995   \n",
       "2  2017-01-05 00:00:00  29.152500  83.680000  39.022499   NaN  158.710007   \n",
       "3  2017-01-06 00:00:00  29.477501  84.800003  39.799500   NaN  159.100006   \n",
       "4  2017-01-09 00:00:00  29.747499  85.480003  39.846001   NaN  158.320007   \n",
       "\n",
       "         BAC        CAH        COST        CVS  ...       PCAR        PSX  \\\n",
       "0  22.530001  74.480003  159.729996  80.349998  ...  43.546665  86.790001   \n",
       "1  22.950001  75.629997  159.759995  79.750000  ...  44.146667  87.260002   \n",
       "2  22.680000  74.500000  162.910004  81.419998  ...  43.426666  86.739998   \n",
       "3  22.680000  75.330002  162.830002  82.199997  ...  43.919998  85.400002   \n",
       "4  22.549999  74.760002  160.970001  81.699997  ...  43.380001  84.019997   \n",
       "\n",
       "           T         UNH         UNP         VZ        WBA        WFC  \\\n",
       "0  32.492447  161.449997  102.519997  54.580002  82.959999  56.000000   \n",
       "1  32.303623  161.910004  103.139999  54.520000  82.980003  56.049999   \n",
       "2  32.212990  162.179993  102.129997  54.639999  83.029999  55.180000   \n",
       "3  31.208460  162.410004  103.190002  53.259998  83.099998  55.040001   \n",
       "4  30.815710  161.949997  102.419998  52.680000  82.550003  54.240002   \n",
       "\n",
       "         WMT        XOM  \n",
       "0  68.660004  90.889999  \n",
       "1  69.059998  89.889999  \n",
       "2  69.209999  88.550003  \n",
       "3  68.260002  88.500000  \n",
       "4  68.709999  87.040001  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s = pd.DataFrame();\n",
    "data_file = \"per-day-fortune-30-company-stock-price-data.csv\";\n",
    "df_s = pd.read_csv(\"./data/\" + data_file, low_memory = False);\n",
    "df_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see ANTM stock price data is empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cure data such as replace missing/null values, use correct data type, sort by date (not really requured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>ANTM</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>CAH</th>\n",
       "      <th>COST</th>\n",
       "      <th>CVS</th>\n",
       "      <th>...</th>\n",
       "      <th>PCAR</th>\n",
       "      <th>PSX</th>\n",
       "      <th>T</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>29.037500</td>\n",
       "      <td>82.610001</td>\n",
       "      <td>37.683498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.970001</td>\n",
       "      <td>22.530001</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>159.729996</td>\n",
       "      <td>80.349998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.546665</td>\n",
       "      <td>86.790001</td>\n",
       "      <td>32.492447</td>\n",
       "      <td>161.449997</td>\n",
       "      <td>102.519997</td>\n",
       "      <td>54.580002</td>\n",
       "      <td>82.959999</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>68.660004</td>\n",
       "      <td>90.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>29.004999</td>\n",
       "      <td>84.660004</td>\n",
       "      <td>37.859001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.619995</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>75.629997</td>\n",
       "      <td>159.759995</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.146667</td>\n",
       "      <td>87.260002</td>\n",
       "      <td>32.303623</td>\n",
       "      <td>161.910004</td>\n",
       "      <td>103.139999</td>\n",
       "      <td>54.520000</td>\n",
       "      <td>82.980003</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>69.059998</td>\n",
       "      <td>89.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>29.152500</td>\n",
       "      <td>83.680000</td>\n",
       "      <td>39.022499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.710007</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>162.910004</td>\n",
       "      <td>81.419998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.426666</td>\n",
       "      <td>86.739998</td>\n",
       "      <td>32.212990</td>\n",
       "      <td>162.179993</td>\n",
       "      <td>102.129997</td>\n",
       "      <td>54.639999</td>\n",
       "      <td>83.029999</td>\n",
       "      <td>55.180000</td>\n",
       "      <td>69.209999</td>\n",
       "      <td>88.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>29.477501</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>39.799500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.100006</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>75.330002</td>\n",
       "      <td>162.830002</td>\n",
       "      <td>82.199997</td>\n",
       "      <td>...</td>\n",
       "      <td>43.919998</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>31.208460</td>\n",
       "      <td>162.410004</td>\n",
       "      <td>103.190002</td>\n",
       "      <td>53.259998</td>\n",
       "      <td>83.099998</td>\n",
       "      <td>55.040001</td>\n",
       "      <td>68.260002</td>\n",
       "      <td>88.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>29.747499</td>\n",
       "      <td>85.480003</td>\n",
       "      <td>39.846001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.320007</td>\n",
       "      <td>22.549999</td>\n",
       "      <td>74.760002</td>\n",
       "      <td>160.970001</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>84.019997</td>\n",
       "      <td>30.815710</td>\n",
       "      <td>161.949997</td>\n",
       "      <td>102.419998</td>\n",
       "      <td>52.680000</td>\n",
       "      <td>82.550003</td>\n",
       "      <td>54.240002</td>\n",
       "      <td>68.709999</td>\n",
       "      <td>87.040001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       AAPL        ABC       AMZN  ANTM          BA        BAC  \\\n",
       "0 2017-01-03  29.037500  82.610001  37.683498   NaN  156.970001  22.530001   \n",
       "1 2017-01-04  29.004999  84.660004  37.859001   NaN  158.619995  22.950001   \n",
       "2 2017-01-05  29.152500  83.680000  39.022499   NaN  158.710007  22.680000   \n",
       "3 2017-01-06  29.477501  84.800003  39.799500   NaN  159.100006  22.680000   \n",
       "4 2017-01-09  29.747499  85.480003  39.846001   NaN  158.320007  22.549999   \n",
       "\n",
       "         CAH        COST        CVS  ...       PCAR        PSX          T  \\\n",
       "0  74.480003  159.729996  80.349998  ...  43.546665  86.790001  32.492447   \n",
       "1  75.629997  159.759995  79.750000  ...  44.146667  87.260002  32.303623   \n",
       "2  74.500000  162.910004  81.419998  ...  43.426666  86.739998  32.212990   \n",
       "3  75.330002  162.830002  82.199997  ...  43.919998  85.400002  31.208460   \n",
       "4  74.760002  160.970001  81.699997  ...  43.380001  84.019997  30.815710   \n",
       "\n",
       "          UNH         UNP         VZ        WBA        WFC        WMT  \\\n",
       "0  161.449997  102.519997  54.580002  82.959999  56.000000  68.660004   \n",
       "1  161.910004  103.139999  54.520000  82.980003  56.049999  69.059998   \n",
       "2  162.179993  102.129997  54.639999  83.029999  55.180000  69.209999   \n",
       "3  162.410004  103.190002  53.259998  83.099998  55.040001  68.260002   \n",
       "4  161.949997  102.419998  52.680000  82.550003  54.240002  68.709999   \n",
       "\n",
       "         XOM  \n",
       "0  90.889999  \n",
       "1  89.889999  \n",
       "2  88.550003  \n",
       "3  88.500000  \n",
       "4  87.040001  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert Date field to be a Date Type\n",
    "df_s[\"Date\"] = df_s[\"Date\"].astype('datetime64[ns]')\n",
    "\n",
    "# Sort data by date although this is no longer needed as data already is sorted when I generated data\n",
    "# df_s = df_s.sort_values( by = ['Ticker','Date'], ascending = True )\n",
    "df_s = df_s.sort_values( by = 'Date', ascending = True )\n",
    "df_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred. Operation ignored\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>ANTM</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>CAH</th>\n",
       "      <th>COST</th>\n",
       "      <th>CVS</th>\n",
       "      <th>...</th>\n",
       "      <th>PCAR</th>\n",
       "      <th>PSX</th>\n",
       "      <th>T</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>29.037500</td>\n",
       "      <td>82.610001</td>\n",
       "      <td>37.683498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.970001</td>\n",
       "      <td>22.530001</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>159.729996</td>\n",
       "      <td>80.349998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.546665</td>\n",
       "      <td>86.790001</td>\n",
       "      <td>32.492447</td>\n",
       "      <td>161.449997</td>\n",
       "      <td>102.519997</td>\n",
       "      <td>54.580002</td>\n",
       "      <td>82.959999</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>68.660004</td>\n",
       "      <td>90.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>29.004999</td>\n",
       "      <td>84.660004</td>\n",
       "      <td>37.859001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.619995</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>75.629997</td>\n",
       "      <td>159.759995</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.146667</td>\n",
       "      <td>87.260002</td>\n",
       "      <td>32.303623</td>\n",
       "      <td>161.910004</td>\n",
       "      <td>103.139999</td>\n",
       "      <td>54.520000</td>\n",
       "      <td>82.980003</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>69.059998</td>\n",
       "      <td>89.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>29.152500</td>\n",
       "      <td>83.680000</td>\n",
       "      <td>39.022499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.710007</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>162.910004</td>\n",
       "      <td>81.419998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.426666</td>\n",
       "      <td>86.739998</td>\n",
       "      <td>32.212990</td>\n",
       "      <td>162.179993</td>\n",
       "      <td>102.129997</td>\n",
       "      <td>54.639999</td>\n",
       "      <td>83.029999</td>\n",
       "      <td>55.180000</td>\n",
       "      <td>69.209999</td>\n",
       "      <td>88.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>29.477501</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>39.799500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.100006</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>75.330002</td>\n",
       "      <td>162.830002</td>\n",
       "      <td>82.199997</td>\n",
       "      <td>...</td>\n",
       "      <td>43.919998</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>31.208460</td>\n",
       "      <td>162.410004</td>\n",
       "      <td>103.190002</td>\n",
       "      <td>53.259998</td>\n",
       "      <td>83.099998</td>\n",
       "      <td>55.040001</td>\n",
       "      <td>68.260002</td>\n",
       "      <td>88.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>29.747499</td>\n",
       "      <td>85.480003</td>\n",
       "      <td>39.846001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.320007</td>\n",
       "      <td>22.549999</td>\n",
       "      <td>74.760002</td>\n",
       "      <td>160.970001</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>84.019997</td>\n",
       "      <td>30.815710</td>\n",
       "      <td>161.949997</td>\n",
       "      <td>102.419998</td>\n",
       "      <td>52.680000</td>\n",
       "      <td>82.550003</td>\n",
       "      <td>54.240002</td>\n",
       "      <td>68.709999</td>\n",
       "      <td>87.040001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>85.599998</td>\n",
       "      <td>89.650002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337.549988</td>\n",
       "      <td>35.169998</td>\n",
       "      <td>51.130001</td>\n",
       "      <td>293.309998</td>\n",
       "      <td>74.379997</td>\n",
       "      <td>...</td>\n",
       "      <td>53.033333</td>\n",
       "      <td>112.669998</td>\n",
       "      <td>29.509064</td>\n",
       "      <td>295.089996</td>\n",
       "      <td>179.419998</td>\n",
       "      <td>61.400002</td>\n",
       "      <td>58.570000</td>\n",
       "      <td>53.810001</td>\n",
       "      <td>119.029999</td>\n",
       "      <td>70.290001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>71.067497</td>\n",
       "      <td>85.419998</td>\n",
       "      <td>89.460503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>35.220001</td>\n",
       "      <td>51.290001</td>\n",
       "      <td>294.230011</td>\n",
       "      <td>74.510002</td>\n",
       "      <td>...</td>\n",
       "      <td>52.993332</td>\n",
       "      <td>113.199997</td>\n",
       "      <td>29.425982</td>\n",
       "      <td>294.540009</td>\n",
       "      <td>179.889999</td>\n",
       "      <td>61.279999</td>\n",
       "      <td>58.349998</td>\n",
       "      <td>53.820000</td>\n",
       "      <td>119.510002</td>\n",
       "      <td>70.019997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>72.477501</td>\n",
       "      <td>85.050003</td>\n",
       "      <td>93.438499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>329.920013</td>\n",
       "      <td>35.520000</td>\n",
       "      <td>51.169998</td>\n",
       "      <td>295.730011</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>...</td>\n",
       "      <td>53.006668</td>\n",
       "      <td>112.059998</td>\n",
       "      <td>29.577040</td>\n",
       "      <td>295.649994</td>\n",
       "      <td>180.809998</td>\n",
       "      <td>61.290001</td>\n",
       "      <td>58.900002</td>\n",
       "      <td>54.150002</td>\n",
       "      <td>119.519997</td>\n",
       "      <td>70.129997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>72.449997</td>\n",
       "      <td>84.910004</td>\n",
       "      <td>93.489998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330.140015</td>\n",
       "      <td>35.349998</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>294.109985</td>\n",
       "      <td>74.400002</td>\n",
       "      <td>...</td>\n",
       "      <td>52.939999</td>\n",
       "      <td>110.599998</td>\n",
       "      <td>29.637463</td>\n",
       "      <td>295.970001</td>\n",
       "      <td>181.410004</td>\n",
       "      <td>61.529999</td>\n",
       "      <td>59.020000</td>\n",
       "      <td>53.919998</td>\n",
       "      <td>119.589996</td>\n",
       "      <td>69.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>72.879997</td>\n",
       "      <td>83.639999</td>\n",
       "      <td>92.344498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>326.399994</td>\n",
       "      <td>35.150002</td>\n",
       "      <td>50.770000</td>\n",
       "      <td>295.140015</td>\n",
       "      <td>73.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>52.646667</td>\n",
       "      <td>110.370003</td>\n",
       "      <td>29.486404</td>\n",
       "      <td>293.850006</td>\n",
       "      <td>180.149994</td>\n",
       "      <td>61.209999</td>\n",
       "      <td>58.910000</td>\n",
       "      <td>53.599998</td>\n",
       "      <td>119.400002</td>\n",
       "      <td>69.480003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       AAPL        ABC       AMZN  ANTM          BA        BAC  \\\n",
       "0   2017-01-03  29.037500  82.610001  37.683498   NaN  156.970001  22.530001   \n",
       "1   2017-01-04  29.004999  84.660004  37.859001   NaN  158.619995  22.950001   \n",
       "2   2017-01-05  29.152500  83.680000  39.022499   NaN  158.710007  22.680000   \n",
       "3   2017-01-06  29.477501  84.800003  39.799500   NaN  159.100006  22.680000   \n",
       "4   2017-01-09  29.747499  85.480003  39.846001   NaN  158.320007  22.549999   \n",
       "..         ...        ...        ...        ...   ...         ...        ...   \n",
       "748 2019-12-23  71.000000  85.599998  89.650002   NaN  337.549988  35.169998   \n",
       "749 2019-12-24  71.067497  85.419998  89.460503   NaN  333.000000  35.220001   \n",
       "750 2019-12-26  72.477501  85.050003  93.438499   NaN  329.920013  35.520000   \n",
       "751 2019-12-27  72.449997  84.910004  93.489998   NaN  330.140015  35.349998   \n",
       "752 2019-12-30  72.879997  83.639999  92.344498   NaN  326.399994  35.150002   \n",
       "\n",
       "           CAH        COST        CVS  ...       PCAR         PSX          T  \\\n",
       "0    74.480003  159.729996  80.349998  ...  43.546665   86.790001  32.492447   \n",
       "1    75.629997  159.759995  79.750000  ...  44.146667   87.260002  32.303623   \n",
       "2    74.500000  162.910004  81.419998  ...  43.426666   86.739998  32.212990   \n",
       "3    75.330002  162.830002  82.199997  ...  43.919998   85.400002  31.208460   \n",
       "4    74.760002  160.970001  81.699997  ...  43.380001   84.019997  30.815710   \n",
       "..         ...         ...        ...  ...        ...         ...        ...   \n",
       "748  51.130001  293.309998  74.379997  ...  53.033333  112.669998  29.509064   \n",
       "749  51.290001  294.230011  74.510002  ...  52.993332  113.199997  29.425982   \n",
       "750  51.169998  295.730011  74.480003  ...  53.006668  112.059998  29.577040   \n",
       "751  51.500000  294.109985  74.400002  ...  52.939999  110.599998  29.637463   \n",
       "752  50.770000  295.140015  73.699997  ...  52.646667  110.370003  29.486404   \n",
       "\n",
       "            UNH         UNP         VZ        WBA        WFC         WMT  \\\n",
       "0    161.449997  102.519997  54.580002  82.959999  56.000000   68.660004   \n",
       "1    161.910004  103.139999  54.520000  82.980003  56.049999   69.059998   \n",
       "2    162.179993  102.129997  54.639999  83.029999  55.180000   69.209999   \n",
       "3    162.410004  103.190002  53.259998  83.099998  55.040001   68.260002   \n",
       "4    161.949997  102.419998  52.680000  82.550003  54.240002   68.709999   \n",
       "..          ...         ...        ...        ...        ...         ...   \n",
       "748  295.089996  179.419998  61.400002  58.570000  53.810001  119.029999   \n",
       "749  294.540009  179.889999  61.279999  58.349998  53.820000  119.510002   \n",
       "750  295.649994  180.809998  61.290001  58.900002  54.150002  119.519997   \n",
       "751  295.970001  181.410004  61.529999  59.020000  53.919998  119.589996   \n",
       "752  293.850006  180.149994  61.209999  58.910000  53.599998  119.400002   \n",
       "\n",
       "           XOM  \n",
       "0    90.889999  \n",
       "1    89.889999  \n",
       "2    88.550003  \n",
       "3    88.500000  \n",
       "4    87.040001  \n",
       "..         ...  \n",
       "748  70.290001  \n",
       "749  70.019997  \n",
       "750  70.129997  \n",
       "751  69.889999  \n",
       "752  69.480003  \n",
       "\n",
       "[753 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html\n",
    "df_s_transpose = df_s\n",
    "\n",
    "try:\n",
    "  df_s_transpose = df_s_transpose.interpolate(inplace = False)\n",
    "except:\n",
    "  print(\"An exception occurred. Operation ignored\")\n",
    "  exit\n",
    "\n",
    "# check if any value is null    \n",
    "df_s_transpose.isnull().values.any()\n",
    "\n",
    "# check if any column (axis=1) is null\n",
    "df_s_transpose[df_s_transpose.isna().any(axis = 1)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>ANTM</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>CAH</th>\n",
       "      <th>COST</th>\n",
       "      <th>CVS</th>\n",
       "      <th>...</th>\n",
       "      <th>PCAR</th>\n",
       "      <th>PSX</th>\n",
       "      <th>T</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>29.037500</td>\n",
       "      <td>82.610001</td>\n",
       "      <td>37.683498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.970001</td>\n",
       "      <td>22.530001</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>159.729996</td>\n",
       "      <td>80.349998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.546665</td>\n",
       "      <td>86.790001</td>\n",
       "      <td>32.492447</td>\n",
       "      <td>161.449997</td>\n",
       "      <td>102.519997</td>\n",
       "      <td>54.580002</td>\n",
       "      <td>82.959999</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>68.660004</td>\n",
       "      <td>90.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>29.004999</td>\n",
       "      <td>84.660004</td>\n",
       "      <td>37.859001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.619995</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>75.629997</td>\n",
       "      <td>159.759995</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.146667</td>\n",
       "      <td>87.260002</td>\n",
       "      <td>32.303623</td>\n",
       "      <td>161.910004</td>\n",
       "      <td>103.139999</td>\n",
       "      <td>54.520000</td>\n",
       "      <td>82.980003</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>69.059998</td>\n",
       "      <td>89.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>29.152500</td>\n",
       "      <td>83.680000</td>\n",
       "      <td>39.022499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.710007</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>162.910004</td>\n",
       "      <td>81.419998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.426666</td>\n",
       "      <td>86.739998</td>\n",
       "      <td>32.212990</td>\n",
       "      <td>162.179993</td>\n",
       "      <td>102.129997</td>\n",
       "      <td>54.639999</td>\n",
       "      <td>83.029999</td>\n",
       "      <td>55.180000</td>\n",
       "      <td>69.209999</td>\n",
       "      <td>88.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>29.477501</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>39.799500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.100006</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>75.330002</td>\n",
       "      <td>162.830002</td>\n",
       "      <td>82.199997</td>\n",
       "      <td>...</td>\n",
       "      <td>43.919998</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>31.208460</td>\n",
       "      <td>162.410004</td>\n",
       "      <td>103.190002</td>\n",
       "      <td>53.259998</td>\n",
       "      <td>83.099998</td>\n",
       "      <td>55.040001</td>\n",
       "      <td>68.260002</td>\n",
       "      <td>88.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>29.747499</td>\n",
       "      <td>85.480003</td>\n",
       "      <td>39.846001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.320007</td>\n",
       "      <td>22.549999</td>\n",
       "      <td>74.760002</td>\n",
       "      <td>160.970001</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>84.019997</td>\n",
       "      <td>30.815710</td>\n",
       "      <td>161.949997</td>\n",
       "      <td>102.419998</td>\n",
       "      <td>52.680000</td>\n",
       "      <td>82.550003</td>\n",
       "      <td>54.240002</td>\n",
       "      <td>68.709999</td>\n",
       "      <td>87.040001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>85.599998</td>\n",
       "      <td>89.650002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337.549988</td>\n",
       "      <td>35.169998</td>\n",
       "      <td>51.130001</td>\n",
       "      <td>293.309998</td>\n",
       "      <td>74.379997</td>\n",
       "      <td>...</td>\n",
       "      <td>53.033333</td>\n",
       "      <td>112.669998</td>\n",
       "      <td>29.509064</td>\n",
       "      <td>295.089996</td>\n",
       "      <td>179.419998</td>\n",
       "      <td>61.400002</td>\n",
       "      <td>58.570000</td>\n",
       "      <td>53.810001</td>\n",
       "      <td>119.029999</td>\n",
       "      <td>70.290001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>71.067497</td>\n",
       "      <td>85.419998</td>\n",
       "      <td>89.460503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>35.220001</td>\n",
       "      <td>51.290001</td>\n",
       "      <td>294.230011</td>\n",
       "      <td>74.510002</td>\n",
       "      <td>...</td>\n",
       "      <td>52.993332</td>\n",
       "      <td>113.199997</td>\n",
       "      <td>29.425982</td>\n",
       "      <td>294.540009</td>\n",
       "      <td>179.889999</td>\n",
       "      <td>61.279999</td>\n",
       "      <td>58.349998</td>\n",
       "      <td>53.820000</td>\n",
       "      <td>119.510002</td>\n",
       "      <td>70.019997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>72.477501</td>\n",
       "      <td>85.050003</td>\n",
       "      <td>93.438499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>329.920013</td>\n",
       "      <td>35.520000</td>\n",
       "      <td>51.169998</td>\n",
       "      <td>295.730011</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>...</td>\n",
       "      <td>53.006668</td>\n",
       "      <td>112.059998</td>\n",
       "      <td>29.577040</td>\n",
       "      <td>295.649994</td>\n",
       "      <td>180.809998</td>\n",
       "      <td>61.290001</td>\n",
       "      <td>58.900002</td>\n",
       "      <td>54.150002</td>\n",
       "      <td>119.519997</td>\n",
       "      <td>70.129997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>72.449997</td>\n",
       "      <td>84.910004</td>\n",
       "      <td>93.489998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330.140015</td>\n",
       "      <td>35.349998</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>294.109985</td>\n",
       "      <td>74.400002</td>\n",
       "      <td>...</td>\n",
       "      <td>52.939999</td>\n",
       "      <td>110.599998</td>\n",
       "      <td>29.637463</td>\n",
       "      <td>295.970001</td>\n",
       "      <td>181.410004</td>\n",
       "      <td>61.529999</td>\n",
       "      <td>59.020000</td>\n",
       "      <td>53.919998</td>\n",
       "      <td>119.589996</td>\n",
       "      <td>69.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>72.879997</td>\n",
       "      <td>83.639999</td>\n",
       "      <td>92.344498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>326.399994</td>\n",
       "      <td>35.150002</td>\n",
       "      <td>50.770000</td>\n",
       "      <td>295.140015</td>\n",
       "      <td>73.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>52.646667</td>\n",
       "      <td>110.370003</td>\n",
       "      <td>29.486404</td>\n",
       "      <td>293.850006</td>\n",
       "      <td>180.149994</td>\n",
       "      <td>61.209999</td>\n",
       "      <td>58.910000</td>\n",
       "      <td>53.599998</td>\n",
       "      <td>119.400002</td>\n",
       "      <td>69.480003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       AAPL        ABC       AMZN  ANTM          BA        BAC  \\\n",
       "0   2017-01-03  29.037500  82.610001  37.683498   NaN  156.970001  22.530001   \n",
       "1   2017-01-04  29.004999  84.660004  37.859001   NaN  158.619995  22.950001   \n",
       "2   2017-01-05  29.152500  83.680000  39.022499   NaN  158.710007  22.680000   \n",
       "3   2017-01-06  29.477501  84.800003  39.799500   NaN  159.100006  22.680000   \n",
       "4   2017-01-09  29.747499  85.480003  39.846001   NaN  158.320007  22.549999   \n",
       "..         ...        ...        ...        ...   ...         ...        ...   \n",
       "748 2019-12-23  71.000000  85.599998  89.650002   NaN  337.549988  35.169998   \n",
       "749 2019-12-24  71.067497  85.419998  89.460503   NaN  333.000000  35.220001   \n",
       "750 2019-12-26  72.477501  85.050003  93.438499   NaN  329.920013  35.520000   \n",
       "751 2019-12-27  72.449997  84.910004  93.489998   NaN  330.140015  35.349998   \n",
       "752 2019-12-30  72.879997  83.639999  92.344498   NaN  326.399994  35.150002   \n",
       "\n",
       "           CAH        COST        CVS  ...       PCAR         PSX          T  \\\n",
       "0    74.480003  159.729996  80.349998  ...  43.546665   86.790001  32.492447   \n",
       "1    75.629997  159.759995  79.750000  ...  44.146667   87.260002  32.303623   \n",
       "2    74.500000  162.910004  81.419998  ...  43.426666   86.739998  32.212990   \n",
       "3    75.330002  162.830002  82.199997  ...  43.919998   85.400002  31.208460   \n",
       "4    74.760002  160.970001  81.699997  ...  43.380001   84.019997  30.815710   \n",
       "..         ...         ...        ...  ...        ...         ...        ...   \n",
       "748  51.130001  293.309998  74.379997  ...  53.033333  112.669998  29.509064   \n",
       "749  51.290001  294.230011  74.510002  ...  52.993332  113.199997  29.425982   \n",
       "750  51.169998  295.730011  74.480003  ...  53.006668  112.059998  29.577040   \n",
       "751  51.500000  294.109985  74.400002  ...  52.939999  110.599998  29.637463   \n",
       "752  50.770000  295.140015  73.699997  ...  52.646667  110.370003  29.486404   \n",
       "\n",
       "            UNH         UNP         VZ        WBA        WFC         WMT  \\\n",
       "0    161.449997  102.519997  54.580002  82.959999  56.000000   68.660004   \n",
       "1    161.910004  103.139999  54.520000  82.980003  56.049999   69.059998   \n",
       "2    162.179993  102.129997  54.639999  83.029999  55.180000   69.209999   \n",
       "3    162.410004  103.190002  53.259998  83.099998  55.040001   68.260002   \n",
       "4    161.949997  102.419998  52.680000  82.550003  54.240002   68.709999   \n",
       "..          ...         ...        ...        ...        ...         ...   \n",
       "748  295.089996  179.419998  61.400002  58.570000  53.810001  119.029999   \n",
       "749  294.540009  179.889999  61.279999  58.349998  53.820000  119.510002   \n",
       "750  295.649994  180.809998  61.290001  58.900002  54.150002  119.519997   \n",
       "751  295.970001  181.410004  61.529999  59.020000  53.919998  119.589996   \n",
       "752  293.850006  180.149994  61.209999  58.910000  53.599998  119.400002   \n",
       "\n",
       "           XOM  \n",
       "0    90.889999  \n",
       "1    89.889999  \n",
       "2    88.550003  \n",
       "3    88.500000  \n",
       "4    87.040001  \n",
       "..         ...  \n",
       "748  70.290001  \n",
       "749  70.019997  \n",
       "750  70.129997  \n",
       "751  69.889999  \n",
       "752  69.480003  \n",
       "\n",
       "[753 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>CAH</th>\n",
       "      <th>COST</th>\n",
       "      <th>CVS</th>\n",
       "      <th>CVX</th>\n",
       "      <th>...</th>\n",
       "      <th>PCAR</th>\n",
       "      <th>PSX</th>\n",
       "      <th>T</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>29.037500</td>\n",
       "      <td>82.610001</td>\n",
       "      <td>37.683498</td>\n",
       "      <td>156.970001</td>\n",
       "      <td>22.530001</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>159.729996</td>\n",
       "      <td>80.349998</td>\n",
       "      <td>117.849998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.546665</td>\n",
       "      <td>86.790001</td>\n",
       "      <td>32.492447</td>\n",
       "      <td>161.449997</td>\n",
       "      <td>102.519997</td>\n",
       "      <td>54.580002</td>\n",
       "      <td>82.959999</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>68.660004</td>\n",
       "      <td>90.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>29.004999</td>\n",
       "      <td>84.660004</td>\n",
       "      <td>37.859001</td>\n",
       "      <td>158.619995</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>75.629997</td>\n",
       "      <td>159.759995</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>117.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.146667</td>\n",
       "      <td>87.260002</td>\n",
       "      <td>32.303623</td>\n",
       "      <td>161.910004</td>\n",
       "      <td>103.139999</td>\n",
       "      <td>54.520000</td>\n",
       "      <td>82.980003</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>69.059998</td>\n",
       "      <td>89.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>29.152500</td>\n",
       "      <td>83.680000</td>\n",
       "      <td>39.022499</td>\n",
       "      <td>158.710007</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>162.910004</td>\n",
       "      <td>81.419998</td>\n",
       "      <td>117.309998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.426666</td>\n",
       "      <td>86.739998</td>\n",
       "      <td>32.212990</td>\n",
       "      <td>162.179993</td>\n",
       "      <td>102.129997</td>\n",
       "      <td>54.639999</td>\n",
       "      <td>83.029999</td>\n",
       "      <td>55.180000</td>\n",
       "      <td>69.209999</td>\n",
       "      <td>88.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>29.477501</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>39.799500</td>\n",
       "      <td>159.100006</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>75.330002</td>\n",
       "      <td>162.830002</td>\n",
       "      <td>82.199997</td>\n",
       "      <td>116.839996</td>\n",
       "      <td>...</td>\n",
       "      <td>43.919998</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>31.208460</td>\n",
       "      <td>162.410004</td>\n",
       "      <td>103.190002</td>\n",
       "      <td>53.259998</td>\n",
       "      <td>83.099998</td>\n",
       "      <td>55.040001</td>\n",
       "      <td>68.260002</td>\n",
       "      <td>88.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>29.747499</td>\n",
       "      <td>85.480003</td>\n",
       "      <td>39.846001</td>\n",
       "      <td>158.320007</td>\n",
       "      <td>22.549999</td>\n",
       "      <td>74.760002</td>\n",
       "      <td>160.970001</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>115.839996</td>\n",
       "      <td>...</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>84.019997</td>\n",
       "      <td>30.815710</td>\n",
       "      <td>161.949997</td>\n",
       "      <td>102.419998</td>\n",
       "      <td>52.680000</td>\n",
       "      <td>82.550003</td>\n",
       "      <td>54.240002</td>\n",
       "      <td>68.709999</td>\n",
       "      <td>87.040001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       AAPL        ABC       AMZN          BA        BAC  \\\n",
       "0 2017-01-03  29.037500  82.610001  37.683498  156.970001  22.530001   \n",
       "1 2017-01-04  29.004999  84.660004  37.859001  158.619995  22.950001   \n",
       "2 2017-01-05  29.152500  83.680000  39.022499  158.710007  22.680000   \n",
       "3 2017-01-06  29.477501  84.800003  39.799500  159.100006  22.680000   \n",
       "4 2017-01-09  29.747499  85.480003  39.846001  158.320007  22.549999   \n",
       "\n",
       "         CAH        COST        CVS         CVX  ...       PCAR        PSX  \\\n",
       "0  74.480003  159.729996  80.349998  117.849998  ...  43.546665  86.790001   \n",
       "1  75.629997  159.759995  79.750000  117.820000  ...  44.146667  87.260002   \n",
       "2  74.500000  162.910004  81.419998  117.309998  ...  43.426666  86.739998   \n",
       "3  75.330002  162.830002  82.199997  116.839996  ...  43.919998  85.400002   \n",
       "4  74.760002  160.970001  81.699997  115.839996  ...  43.380001  84.019997   \n",
       "\n",
       "           T         UNH         UNP         VZ        WBA        WFC  \\\n",
       "0  32.492447  161.449997  102.519997  54.580002  82.959999  56.000000   \n",
       "1  32.303623  161.910004  103.139999  54.520000  82.980003  56.049999   \n",
       "2  32.212990  162.179993  102.129997  54.639999  83.029999  55.180000   \n",
       "3  31.208460  162.410004  103.190002  53.259998  83.099998  55.040001   \n",
       "4  30.815710  161.949997  102.419998  52.680000  82.550003  54.240002   \n",
       "\n",
       "         WMT        XOM  \n",
       "0  68.660004  90.889999  \n",
       "1  69.059998  89.889999  \n",
       "2  69.209999  88.550003  \n",
       "3  68.260002  88.500000  \n",
       "4  68.709999  87.040001  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_s_transpose = df_s\n",
    "\n",
    "if drop_cols_with_na == 1:\n",
    "    df_s_transpose = df_s_transpose.dropna(axis = 1);    \n",
    "   \n",
    "print(df_s_transpose.shape)\n",
    "df_s_transpose.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>CAH</th>\n",
       "      <th>COST</th>\n",
       "      <th>CVS</th>\n",
       "      <th>CVX</th>\n",
       "      <th>...</th>\n",
       "      <th>PCAR</th>\n",
       "      <th>PSX</th>\n",
       "      <th>T</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, AAPL, ABC, AMZN, BA, BAC, CAH, COST, CVS, CVX, F, GE, GM, GOOGL, HD, JPM, KR, MCK, MSFT, PCAR, PSX, T, UNH, UNP, VZ, WBA, WFC, WMT, XOM]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# further check and verify\n",
    "df_s_transpose.isnull().values.any()\n",
    "df_s_transpose[df_s_transpose.isna().any( axis = 1 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the date column as the index column for the dataset\n",
    "# df_s_transpose.index = df_s_transpose['Date']\n",
    "df_s_transpose.index = df_s_transpose.index.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXauDrpHbcE3"
   },
   "source": [
    "# Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 649,
     "status": "ok",
     "timestamp": 1678154403155,
     "user": {
      "displayName": "Sayed Ahmed",
      "userId": "06810739430240035128"
     },
     "user_tz": 300
    },
    "id": "BQ3QiHQBV0X1",
    "outputId": "dcfb64df-b60b-46b1-d20e-7961ae8f655f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>CAH</th>\n",
       "      <th>COST</th>\n",
       "      <th>CVS</th>\n",
       "      <th>CVX</th>\n",
       "      <th>F</th>\n",
       "      <th>...</th>\n",
       "      <th>PCAR</th>\n",
       "      <th>PSX</th>\n",
       "      <th>T</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036748</td>\n",
       "      <td>0.786106</td>\n",
       "      <td>0.692570</td>\n",
       "      <td>0.763609</td>\n",
       "      <td>-0.666770</td>\n",
       "      <td>0.863643</td>\n",
       "      <td>-0.342350</td>\n",
       "      <td>0.459125</td>\n",
       "      <td>-0.593845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427859</td>\n",
       "      <td>0.745233</td>\n",
       "      <td>-0.262982</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.798973</td>\n",
       "      <td>0.676181</td>\n",
       "      <td>-0.658245</td>\n",
       "      <td>-0.197965</td>\n",
       "      <td>0.827489</td>\n",
       "      <td>-0.505612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABC</th>\n",
       "      <td>-0.036748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.127768</td>\n",
       "      <td>-0.126217</td>\n",
       "      <td>0.163579</td>\n",
       "      <td>0.466160</td>\n",
       "      <td>-0.130971</td>\n",
       "      <td>0.427752</td>\n",
       "      <td>0.029482</td>\n",
       "      <td>0.302385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154842</td>\n",
       "      <td>0.097029</td>\n",
       "      <td>0.358636</td>\n",
       "      <td>-0.055076</td>\n",
       "      <td>-0.178882</td>\n",
       "      <td>-0.252366</td>\n",
       "      <td>0.300615</td>\n",
       "      <td>0.574354</td>\n",
       "      <td>-0.079702</td>\n",
       "      <td>0.250188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.786106</td>\n",
       "      <td>-0.127768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909833</td>\n",
       "      <td>0.739494</td>\n",
       "      <td>-0.876488</td>\n",
       "      <td>0.826927</td>\n",
       "      <td>-0.673998</td>\n",
       "      <td>0.601387</td>\n",
       "      <td>-0.721688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071989</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>-0.677553</td>\n",
       "      <td>0.886126</td>\n",
       "      <td>0.929052</td>\n",
       "      <td>0.708967</td>\n",
       "      <td>-0.763988</td>\n",
       "      <td>-0.409286</td>\n",
       "      <td>0.765665</td>\n",
       "      <td>-0.457154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>0.692570</td>\n",
       "      <td>-0.126217</td>\n",
       "      <td>0.909833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782307</td>\n",
       "      <td>-0.828416</td>\n",
       "      <td>0.699197</td>\n",
       "      <td>-0.661338</td>\n",
       "      <td>0.662725</td>\n",
       "      <td>-0.672301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103744</td>\n",
       "      <td>0.688694</td>\n",
       "      <td>-0.708575</td>\n",
       "      <td>0.886833</td>\n",
       "      <td>0.873865</td>\n",
       "      <td>0.653679</td>\n",
       "      <td>-0.707509</td>\n",
       "      <td>-0.328412</td>\n",
       "      <td>0.765026</td>\n",
       "      <td>-0.413556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAC</th>\n",
       "      <td>0.763609</td>\n",
       "      <td>0.163579</td>\n",
       "      <td>0.739494</td>\n",
       "      <td>0.782307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.523495</td>\n",
       "      <td>0.613895</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>0.670267</td>\n",
       "      <td>-0.347324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484901</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>-0.315603</td>\n",
       "      <td>0.770331</td>\n",
       "      <td>0.727145</td>\n",
       "      <td>0.485319</td>\n",
       "      <td>-0.604695</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>-0.297798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAH</th>\n",
       "      <td>-0.666770</td>\n",
       "      <td>0.466160</td>\n",
       "      <td>-0.876488</td>\n",
       "      <td>-0.828416</td>\n",
       "      <td>-0.523495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.766108</td>\n",
       "      <td>0.746348</td>\n",
       "      <td>-0.539610</td>\n",
       "      <td>0.709460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059840</td>\n",
       "      <td>-0.558826</td>\n",
       "      <td>0.741128</td>\n",
       "      <td>-0.795163</td>\n",
       "      <td>-0.851249</td>\n",
       "      <td>-0.711528</td>\n",
       "      <td>0.791882</td>\n",
       "      <td>0.596125</td>\n",
       "      <td>-0.739558</td>\n",
       "      <td>0.523205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COST</th>\n",
       "      <td>0.863643</td>\n",
       "      <td>-0.130971</td>\n",
       "      <td>0.826927</td>\n",
       "      <td>0.699197</td>\n",
       "      <td>0.613895</td>\n",
       "      <td>-0.766108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.553276</td>\n",
       "      <td>0.444068</td>\n",
       "      <td>-0.712750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317508</td>\n",
       "      <td>0.541579</td>\n",
       "      <td>-0.297706</td>\n",
       "      <td>0.695051</td>\n",
       "      <td>0.902083</td>\n",
       "      <td>0.864420</td>\n",
       "      <td>-0.766485</td>\n",
       "      <td>-0.473844</td>\n",
       "      <td>0.893336</td>\n",
       "      <td>-0.648205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVS</th>\n",
       "      <td>-0.342350</td>\n",
       "      <td>0.427752</td>\n",
       "      <td>-0.673998</td>\n",
       "      <td>-0.661338</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>0.746348</td>\n",
       "      <td>-0.553276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.440430</td>\n",
       "      <td>0.464550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017925</td>\n",
       "      <td>-0.225111</td>\n",
       "      <td>0.586122</td>\n",
       "      <td>-0.439705</td>\n",
       "      <td>-0.686060</td>\n",
       "      <td>-0.463266</td>\n",
       "      <td>0.850140</td>\n",
       "      <td>0.643467</td>\n",
       "      <td>-0.529032</td>\n",
       "      <td>0.449050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVX</th>\n",
       "      <td>0.459125</td>\n",
       "      <td>0.029482</td>\n",
       "      <td>0.601387</td>\n",
       "      <td>0.662725</td>\n",
       "      <td>0.670267</td>\n",
       "      <td>-0.539610</td>\n",
       "      <td>0.444068</td>\n",
       "      <td>-0.440430</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293140</td>\n",
       "      <td>0.717509</td>\n",
       "      <td>-0.388580</td>\n",
       "      <td>0.594834</td>\n",
       "      <td>0.602565</td>\n",
       "      <td>0.419555</td>\n",
       "      <td>-0.535137</td>\n",
       "      <td>0.040413</td>\n",
       "      <td>0.482086</td>\n",
       "      <td>0.101968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>-0.593845</td>\n",
       "      <td>0.302385</td>\n",
       "      <td>-0.721688</td>\n",
       "      <td>-0.672301</td>\n",
       "      <td>-0.347324</td>\n",
       "      <td>0.709460</td>\n",
       "      <td>-0.712750</td>\n",
       "      <td>0.464550</td>\n",
       "      <td>-0.087233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115762</td>\n",
       "      <td>-0.306461</td>\n",
       "      <td>0.563575</td>\n",
       "      <td>-0.678168</td>\n",
       "      <td>-0.727356</td>\n",
       "      <td>-0.726151</td>\n",
       "      <td>0.467808</td>\n",
       "      <td>0.607512</td>\n",
       "      <td>-0.640430</td>\n",
       "      <td>0.652238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>-0.688955</td>\n",
       "      <td>0.212265</td>\n",
       "      <td>-0.917546</td>\n",
       "      <td>-0.939535</td>\n",
       "      <td>-0.696132</td>\n",
       "      <td>0.900806</td>\n",
       "      <td>-0.757072</td>\n",
       "      <td>0.683847</td>\n",
       "      <td>-0.556104</td>\n",
       "      <td>0.751037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016267</td>\n",
       "      <td>-0.607796</td>\n",
       "      <td>0.749675</td>\n",
       "      <td>-0.899346</td>\n",
       "      <td>-0.882287</td>\n",
       "      <td>-0.729337</td>\n",
       "      <td>0.727638</td>\n",
       "      <td>0.454518</td>\n",
       "      <td>-0.801333</td>\n",
       "      <td>0.554811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>-0.043523</td>\n",
       "      <td>0.032142</td>\n",
       "      <td>-0.007530</td>\n",
       "      <td>0.197818</td>\n",
       "      <td>0.323353</td>\n",
       "      <td>-0.058398</td>\n",
       "      <td>-0.104827</td>\n",
       "      <td>-0.147932</td>\n",
       "      <td>0.512428</td>\n",
       "      <td>0.409949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348596</td>\n",
       "      <td>0.229382</td>\n",
       "      <td>-0.056340</td>\n",
       "      <td>0.089297</td>\n",
       "      <td>0.037898</td>\n",
       "      <td>-0.092822</td>\n",
       "      <td>-0.198215</td>\n",
       "      <td>0.296275</td>\n",
       "      <td>0.138609</td>\n",
       "      <td>0.236213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.888000</td>\n",
       "      <td>-0.064546</td>\n",
       "      <td>0.876585</td>\n",
       "      <td>0.839987</td>\n",
       "      <td>0.841836</td>\n",
       "      <td>-0.757748</td>\n",
       "      <td>0.816834</td>\n",
       "      <td>-0.518179</td>\n",
       "      <td>0.588503</td>\n",
       "      <td>-0.628489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354313</td>\n",
       "      <td>0.768521</td>\n",
       "      <td>-0.465246</td>\n",
       "      <td>0.838787</td>\n",
       "      <td>0.866303</td>\n",
       "      <td>0.667293</td>\n",
       "      <td>-0.742607</td>\n",
       "      <td>-0.192887</td>\n",
       "      <td>0.836321</td>\n",
       "      <td>-0.453943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD</th>\n",
       "      <td>0.877335</td>\n",
       "      <td>-0.012956</td>\n",
       "      <td>0.860812</td>\n",
       "      <td>0.816428</td>\n",
       "      <td>0.792398</td>\n",
       "      <td>-0.762504</td>\n",
       "      <td>0.899330</td>\n",
       "      <td>-0.545253</td>\n",
       "      <td>0.619018</td>\n",
       "      <td>-0.576284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391255</td>\n",
       "      <td>0.733390</td>\n",
       "      <td>-0.344361</td>\n",
       "      <td>0.755492</td>\n",
       "      <td>0.875252</td>\n",
       "      <td>0.714326</td>\n",
       "      <td>-0.805361</td>\n",
       "      <td>-0.262600</td>\n",
       "      <td>0.904232</td>\n",
       "      <td>-0.513920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPM</th>\n",
       "      <td>0.887024</td>\n",
       "      <td>0.080675</td>\n",
       "      <td>0.804708</td>\n",
       "      <td>0.791697</td>\n",
       "      <td>0.947474</td>\n",
       "      <td>-0.630811</td>\n",
       "      <td>0.781794</td>\n",
       "      <td>-0.408974</td>\n",
       "      <td>0.610744</td>\n",
       "      <td>-0.486046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480762</td>\n",
       "      <td>0.791179</td>\n",
       "      <td>-0.306340</td>\n",
       "      <td>0.813623</td>\n",
       "      <td>0.811915</td>\n",
       "      <td>0.645182</td>\n",
       "      <td>-0.685892</td>\n",
       "      <td>-0.048314</td>\n",
       "      <td>0.828651</td>\n",
       "      <td>-0.476361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>-0.116002</td>\n",
       "      <td>0.273424</td>\n",
       "      <td>-0.101880</td>\n",
       "      <td>-0.184247</td>\n",
       "      <td>-0.059548</td>\n",
       "      <td>0.243666</td>\n",
       "      <td>-0.075982</td>\n",
       "      <td>0.426283</td>\n",
       "      <td>-0.101121</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165326</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>0.155794</td>\n",
       "      <td>-0.045956</td>\n",
       "      <td>-0.101779</td>\n",
       "      <td>0.083074</td>\n",
       "      <td>0.462944</td>\n",
       "      <td>0.404527</td>\n",
       "      <td>-0.225411</td>\n",
       "      <td>0.282817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCK</th>\n",
       "      <td>-0.282868</td>\n",
       "      <td>0.670322</td>\n",
       "      <td>-0.559749</td>\n",
       "      <td>-0.491303</td>\n",
       "      <td>-0.150853</td>\n",
       "      <td>0.684527</td>\n",
       "      <td>-0.412378</td>\n",
       "      <td>0.530977</td>\n",
       "      <td>-0.167482</td>\n",
       "      <td>0.654480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307479</td>\n",
       "      <td>-0.160706</td>\n",
       "      <td>0.673269</td>\n",
       "      <td>-0.480768</td>\n",
       "      <td>-0.535813</td>\n",
       "      <td>-0.558568</td>\n",
       "      <td>0.349649</td>\n",
       "      <td>0.518439</td>\n",
       "      <td>-0.279208</td>\n",
       "      <td>0.265308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.881596</td>\n",
       "      <td>-0.186018</td>\n",
       "      <td>0.891483</td>\n",
       "      <td>0.803451</td>\n",
       "      <td>0.699724</td>\n",
       "      <td>-0.838649</td>\n",
       "      <td>0.967020</td>\n",
       "      <td>-0.638668</td>\n",
       "      <td>0.510042</td>\n",
       "      <td>-0.731602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322893</td>\n",
       "      <td>0.591259</td>\n",
       "      <td>-0.432385</td>\n",
       "      <td>0.794765</td>\n",
       "      <td>0.947943</td>\n",
       "      <td>0.840526</td>\n",
       "      <td>-0.836292</td>\n",
       "      <td>-0.500994</td>\n",
       "      <td>0.919066</td>\n",
       "      <td>-0.662010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCAR</th>\n",
       "      <td>0.427859</td>\n",
       "      <td>0.154842</td>\n",
       "      <td>0.071989</td>\n",
       "      <td>0.103744</td>\n",
       "      <td>0.484901</td>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.317508</td>\n",
       "      <td>0.017925</td>\n",
       "      <td>0.293140</td>\n",
       "      <td>0.115762</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250929</td>\n",
       "      <td>0.412006</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.263082</td>\n",
       "      <td>0.235457</td>\n",
       "      <td>-0.295242</td>\n",
       "      <td>0.234356</td>\n",
       "      <td>0.419882</td>\n",
       "      <td>-0.078119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSX</th>\n",
       "      <td>0.745233</td>\n",
       "      <td>0.097029</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>0.688694</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>-0.558826</td>\n",
       "      <td>0.541579</td>\n",
       "      <td>-0.225111</td>\n",
       "      <td>0.717509</td>\n",
       "      <td>-0.306461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.348642</td>\n",
       "      <td>0.736617</td>\n",
       "      <td>0.594746</td>\n",
       "      <td>0.375514</td>\n",
       "      <td>-0.485566</td>\n",
       "      <td>0.152373</td>\n",
       "      <td>0.529770</td>\n",
       "      <td>-0.146648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>-0.262982</td>\n",
       "      <td>0.358636</td>\n",
       "      <td>-0.677553</td>\n",
       "      <td>-0.708575</td>\n",
       "      <td>-0.315603</td>\n",
       "      <td>0.741128</td>\n",
       "      <td>-0.297706</td>\n",
       "      <td>0.586122</td>\n",
       "      <td>-0.388580</td>\n",
       "      <td>0.563575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412006</td>\n",
       "      <td>-0.348642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.703425</td>\n",
       "      <td>-0.558593</td>\n",
       "      <td>-0.335245</td>\n",
       "      <td>0.410818</td>\n",
       "      <td>0.441474</td>\n",
       "      <td>-0.329463</td>\n",
       "      <td>0.166924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNH</th>\n",
       "      <td>0.760652</td>\n",
       "      <td>-0.055076</td>\n",
       "      <td>0.886126</td>\n",
       "      <td>0.886833</td>\n",
       "      <td>0.770331</td>\n",
       "      <td>-0.795163</td>\n",
       "      <td>0.695051</td>\n",
       "      <td>-0.439705</td>\n",
       "      <td>0.594834</td>\n",
       "      <td>-0.678168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.736617</td>\n",
       "      <td>-0.703425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841125</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>-0.559520</td>\n",
       "      <td>-0.233302</td>\n",
       "      <td>0.734507</td>\n",
       "      <td>-0.399068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNP</th>\n",
       "      <td>0.798973</td>\n",
       "      <td>-0.178882</td>\n",
       "      <td>0.929052</td>\n",
       "      <td>0.873865</td>\n",
       "      <td>0.727145</td>\n",
       "      <td>-0.851249</td>\n",
       "      <td>0.902083</td>\n",
       "      <td>-0.686060</td>\n",
       "      <td>0.602565</td>\n",
       "      <td>-0.727356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263082</td>\n",
       "      <td>0.594746</td>\n",
       "      <td>-0.558593</td>\n",
       "      <td>0.841125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.834500</td>\n",
       "      <td>-0.790853</td>\n",
       "      <td>-0.472179</td>\n",
       "      <td>0.854697</td>\n",
       "      <td>-0.520728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VZ</th>\n",
       "      <td>0.676181</td>\n",
       "      <td>-0.252366</td>\n",
       "      <td>0.708967</td>\n",
       "      <td>0.653679</td>\n",
       "      <td>0.485319</td>\n",
       "      <td>-0.711528</td>\n",
       "      <td>0.864420</td>\n",
       "      <td>-0.463266</td>\n",
       "      <td>0.419555</td>\n",
       "      <td>-0.726151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235457</td>\n",
       "      <td>0.375514</td>\n",
       "      <td>-0.335245</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>0.834500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.575865</td>\n",
       "      <td>-0.445419</td>\n",
       "      <td>0.808992</td>\n",
       "      <td>-0.524897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBA</th>\n",
       "      <td>-0.658245</td>\n",
       "      <td>0.300615</td>\n",
       "      <td>-0.763988</td>\n",
       "      <td>-0.707509</td>\n",
       "      <td>-0.604695</td>\n",
       "      <td>0.791882</td>\n",
       "      <td>-0.766485</td>\n",
       "      <td>0.850140</td>\n",
       "      <td>-0.535137</td>\n",
       "      <td>0.467808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295242</td>\n",
       "      <td>-0.485566</td>\n",
       "      <td>0.410818</td>\n",
       "      <td>-0.559520</td>\n",
       "      <td>-0.790853</td>\n",
       "      <td>-0.575865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.531891</td>\n",
       "      <td>-0.752517</td>\n",
       "      <td>0.575520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WFC</th>\n",
       "      <td>-0.197965</td>\n",
       "      <td>0.574354</td>\n",
       "      <td>-0.409286</td>\n",
       "      <td>-0.328412</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.596125</td>\n",
       "      <td>-0.473844</td>\n",
       "      <td>0.643467</td>\n",
       "      <td>0.040413</td>\n",
       "      <td>0.607512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234356</td>\n",
       "      <td>0.152373</td>\n",
       "      <td>0.441474</td>\n",
       "      <td>-0.233302</td>\n",
       "      <td>-0.472179</td>\n",
       "      <td>-0.445419</td>\n",
       "      <td>0.531891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.361995</td>\n",
       "      <td>0.595208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMT</th>\n",
       "      <td>0.827489</td>\n",
       "      <td>-0.079702</td>\n",
       "      <td>0.765665</td>\n",
       "      <td>0.765026</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>-0.739558</td>\n",
       "      <td>0.893336</td>\n",
       "      <td>-0.529032</td>\n",
       "      <td>0.482086</td>\n",
       "      <td>-0.640430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419882</td>\n",
       "      <td>0.529770</td>\n",
       "      <td>-0.329463</td>\n",
       "      <td>0.734507</td>\n",
       "      <td>0.854697</td>\n",
       "      <td>0.808992</td>\n",
       "      <td>-0.752517</td>\n",
       "      <td>-0.361995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.617936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>-0.505612</td>\n",
       "      <td>0.250188</td>\n",
       "      <td>-0.457154</td>\n",
       "      <td>-0.413556</td>\n",
       "      <td>-0.297798</td>\n",
       "      <td>0.523205</td>\n",
       "      <td>-0.648205</td>\n",
       "      <td>0.449050</td>\n",
       "      <td>0.101968</td>\n",
       "      <td>0.652238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078119</td>\n",
       "      <td>-0.146648</td>\n",
       "      <td>0.166924</td>\n",
       "      <td>-0.399068</td>\n",
       "      <td>-0.520728</td>\n",
       "      <td>-0.524897</td>\n",
       "      <td>0.575520</td>\n",
       "      <td>0.595208</td>\n",
       "      <td>-0.617936</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AAPL       ABC      AMZN        BA       BAC       CAH      COST  \\\n",
       "AAPL   1.000000 -0.036748  0.786106  0.692570  0.763609 -0.666770  0.863643   \n",
       "ABC   -0.036748  1.000000 -0.127768 -0.126217  0.163579  0.466160 -0.130971   \n",
       "AMZN   0.786106 -0.127768  1.000000  0.909833  0.739494 -0.876488  0.826927   \n",
       "BA     0.692570 -0.126217  0.909833  1.000000  0.782307 -0.828416  0.699197   \n",
       "BAC    0.763609  0.163579  0.739494  0.782307  1.000000 -0.523495  0.613895   \n",
       "CAH   -0.666770  0.466160 -0.876488 -0.828416 -0.523495  1.000000 -0.766108   \n",
       "COST   0.863643 -0.130971  0.826927  0.699197  0.613895 -0.766108  1.000000   \n",
       "CVS   -0.342350  0.427752 -0.673998 -0.661338 -0.389465  0.746348 -0.553276   \n",
       "CVX    0.459125  0.029482  0.601387  0.662725  0.670267 -0.539610  0.444068   \n",
       "F     -0.593845  0.302385 -0.721688 -0.672301 -0.347324  0.709460 -0.712750   \n",
       "GE    -0.688955  0.212265 -0.917546 -0.939535 -0.696132  0.900806 -0.757072   \n",
       "GM    -0.043523  0.032142 -0.007530  0.197818  0.323353 -0.058398 -0.104827   \n",
       "GOOGL  0.888000 -0.064546  0.876585  0.839987  0.841836 -0.757748  0.816834   \n",
       "HD     0.877335 -0.012956  0.860812  0.816428  0.792398 -0.762504  0.899330   \n",
       "JPM    0.887024  0.080675  0.804708  0.791697  0.947474 -0.630811  0.781794   \n",
       "KR    -0.116002  0.273424 -0.101880 -0.184247 -0.059548  0.243666 -0.075982   \n",
       "MCK   -0.282868  0.670322 -0.559749 -0.491303 -0.150853  0.684527 -0.412378   \n",
       "MSFT   0.881596 -0.186018  0.891483  0.803451  0.699724 -0.838649  0.967020   \n",
       "PCAR   0.427859  0.154842  0.071989  0.103744  0.484901  0.059840  0.317508   \n",
       "PSX    0.745233  0.097029  0.690894  0.688694  0.804676 -0.558826  0.541579   \n",
       "T     -0.262982  0.358636 -0.677553 -0.708575 -0.315603  0.741128 -0.297706   \n",
       "UNH    0.760652 -0.055076  0.886126  0.886833  0.770331 -0.795163  0.695051   \n",
       "UNP    0.798973 -0.178882  0.929052  0.873865  0.727145 -0.851249  0.902083   \n",
       "VZ     0.676181 -0.252366  0.708967  0.653679  0.485319 -0.711528  0.864420   \n",
       "WBA   -0.658245  0.300615 -0.763988 -0.707509 -0.604695  0.791882 -0.766485   \n",
       "WFC   -0.197965  0.574354 -0.409286 -0.328412  0.127918  0.596125 -0.473844   \n",
       "WMT    0.827489 -0.079702  0.765665  0.765026  0.705303 -0.739558  0.893336   \n",
       "XOM   -0.505612  0.250188 -0.457154 -0.413556 -0.297798  0.523205 -0.648205   \n",
       "\n",
       "            CVS       CVX         F  ...      PCAR       PSX         T  \\\n",
       "AAPL  -0.342350  0.459125 -0.593845  ...  0.427859  0.745233 -0.262982   \n",
       "ABC    0.427752  0.029482  0.302385  ...  0.154842  0.097029  0.358636   \n",
       "AMZN  -0.673998  0.601387 -0.721688  ...  0.071989  0.690894 -0.677553   \n",
       "BA    -0.661338  0.662725 -0.672301  ...  0.103744  0.688694 -0.708575   \n",
       "BAC   -0.389465  0.670267 -0.347324  ...  0.484901  0.804676 -0.315603   \n",
       "CAH    0.746348 -0.539610  0.709460  ...  0.059840 -0.558826  0.741128   \n",
       "COST  -0.553276  0.444068 -0.712750  ...  0.317508  0.541579 -0.297706   \n",
       "CVS    1.000000 -0.440430  0.464550  ...  0.017925 -0.225111  0.586122   \n",
       "CVX   -0.440430  1.000000 -0.087233  ...  0.293140  0.717509 -0.388580   \n",
       "F      0.464550 -0.087233  1.000000  ...  0.115762 -0.306461  0.563575   \n",
       "GE     0.683847 -0.556104  0.751037  ...  0.016267 -0.607796  0.749675   \n",
       "GM    -0.147932  0.512428  0.409949  ...  0.348596  0.229382 -0.056340   \n",
       "GOOGL -0.518179  0.588503 -0.628489  ...  0.354313  0.768521 -0.465246   \n",
       "HD    -0.545253  0.619018 -0.576284  ...  0.391255  0.733390 -0.344361   \n",
       "JPM   -0.408974  0.610744 -0.486046  ...  0.480762  0.791179 -0.306340   \n",
       "KR     0.426283 -0.101121  0.008188  ... -0.165326 -0.000130  0.155794   \n",
       "MCK    0.530977 -0.167482  0.654480  ...  0.307479 -0.160706  0.673269   \n",
       "MSFT  -0.638668  0.510042 -0.731602  ...  0.322893  0.591259 -0.432385   \n",
       "PCAR   0.017925  0.293140  0.115762  ...  1.000000  0.250929  0.412006   \n",
       "PSX   -0.225111  0.717509 -0.306461  ...  0.250929  1.000000 -0.348642   \n",
       "T      0.586122 -0.388580  0.563575  ...  0.412006 -0.348642  1.000000   \n",
       "UNH   -0.439705  0.594834 -0.678168  ...  0.088494  0.736617 -0.703425   \n",
       "UNP   -0.686060  0.602565 -0.727356  ...  0.263082  0.594746 -0.558593   \n",
       "VZ    -0.463266  0.419555 -0.726151  ...  0.235457  0.375514 -0.335245   \n",
       "WBA    0.850140 -0.535137  0.467808  ... -0.295242 -0.485566  0.410818   \n",
       "WFC    0.643467  0.040413  0.607512  ...  0.234356  0.152373  0.441474   \n",
       "WMT   -0.529032  0.482086 -0.640430  ...  0.419882  0.529770 -0.329463   \n",
       "XOM    0.449050  0.101968  0.652238  ... -0.078119 -0.146648  0.166924   \n",
       "\n",
       "            UNH       UNP        VZ       WBA       WFC       WMT       XOM  \n",
       "AAPL   0.760652  0.798973  0.676181 -0.658245 -0.197965  0.827489 -0.505612  \n",
       "ABC   -0.055076 -0.178882 -0.252366  0.300615  0.574354 -0.079702  0.250188  \n",
       "AMZN   0.886126  0.929052  0.708967 -0.763988 -0.409286  0.765665 -0.457154  \n",
       "BA     0.886833  0.873865  0.653679 -0.707509 -0.328412  0.765026 -0.413556  \n",
       "BAC    0.770331  0.727145  0.485319 -0.604695  0.127918  0.705303 -0.297798  \n",
       "CAH   -0.795163 -0.851249 -0.711528  0.791882  0.596125 -0.739558  0.523205  \n",
       "COST   0.695051  0.902083  0.864420 -0.766485 -0.473844  0.893336 -0.648205  \n",
       "CVS   -0.439705 -0.686060 -0.463266  0.850140  0.643467 -0.529032  0.449050  \n",
       "CVX    0.594834  0.602565  0.419555 -0.535137  0.040413  0.482086  0.101968  \n",
       "F     -0.678168 -0.727356 -0.726151  0.467808  0.607512 -0.640430  0.652238  \n",
       "GE    -0.899346 -0.882287 -0.729337  0.727638  0.454518 -0.801333  0.554811  \n",
       "GM     0.089297  0.037898 -0.092822 -0.198215  0.296275  0.138609  0.236213  \n",
       "GOOGL  0.838787  0.866303  0.667293 -0.742607 -0.192887  0.836321 -0.453943  \n",
       "HD     0.755492  0.875252  0.714326 -0.805361 -0.262600  0.904232 -0.513920  \n",
       "JPM    0.813623  0.811915  0.645182 -0.685892 -0.048314  0.828651 -0.476361  \n",
       "KR    -0.045956 -0.101779  0.083074  0.462944  0.404527 -0.225411  0.282817  \n",
       "MCK   -0.480768 -0.535813 -0.558568  0.349649  0.518439 -0.279208  0.265308  \n",
       "MSFT   0.794765  0.947943  0.840526 -0.836292 -0.500994  0.919066 -0.662010  \n",
       "PCAR   0.088494  0.263082  0.235457 -0.295242  0.234356  0.419882 -0.078119  \n",
       "PSX    0.736617  0.594746  0.375514 -0.485566  0.152373  0.529770 -0.146648  \n",
       "T     -0.703425 -0.558593 -0.335245  0.410818  0.441474 -0.329463  0.166924  \n",
       "UNH    1.000000  0.841125  0.665200 -0.559520 -0.233302  0.734507 -0.399068  \n",
       "UNP    0.841125  1.000000  0.834500 -0.790853 -0.472179  0.854697 -0.520728  \n",
       "VZ     0.665200  0.834500  1.000000 -0.575865 -0.445419  0.808992 -0.524897  \n",
       "WBA   -0.559520 -0.790853 -0.575865  1.000000  0.531891 -0.752517  0.575520  \n",
       "WFC   -0.233302 -0.472179 -0.445419  0.531891  1.000000 -0.361995  0.595208  \n",
       "WMT    0.734507  0.854697  0.808992 -0.752517 -0.361995  1.000000 -0.617936  \n",
       "XOM   -0.399068 -0.520728 -0.524897  0.575520  0.595208 -0.617936  1.000000  \n",
       "\n",
       "[28 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s_transpose_pearson = df_s_transpose.corr(method = 'pearson', numeric_only = True)\n",
    "df_s_transpose_pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAF7cHrYbWbJ"
   },
   "source": [
    "# Pearson Correlation Coefficient based Adjacency Graph Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1678154403155,
     "user": {
      "displayName": "Sayed Ahmed",
      "userId": "06810739430240035128"
     },
     "user_tz": 300
    },
    "id": "FAKiowgOZkxu",
    "outputId": "1376d8c4-12a0-43ec-f82e-002979c4a7b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>CAH</th>\n",
       "      <th>COST</th>\n",
       "      <th>CVS</th>\n",
       "      <th>CVX</th>\n",
       "      <th>F</th>\n",
       "      <th>...</th>\n",
       "      <th>PCAR</th>\n",
       "      <th>PSX</th>\n",
       "      <th>T</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COST</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVX</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPM</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCAR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSX</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNH</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNP</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VZ</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WFC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMT</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAPL  ABC  AMZN   BA  BAC  CAH  COST  CVS  CVX    F  ...  PCAR  PSX  \\\n",
       "AAPL    1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  0.0  0.0  ...   0.0  1.0   \n",
       "ABC     0.0  1.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
       "AMZN    1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "BA      1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "BAC     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "CAH     0.0  0.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  1.0  ...   0.0  0.0   \n",
       "COST    1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  0.0  0.0  ...   0.0  1.0   \n",
       "CVS     0.0  0.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  0.0  ...   0.0  0.0   \n",
       "CVX     0.0  0.0   1.0  1.0  1.0  0.0   0.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "F       0.0  0.0   0.0  0.0  0.0  1.0   0.0  0.0  0.0  1.0  ...   0.0  0.0   \n",
       "GE      0.0  0.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  1.0  ...   0.0  0.0   \n",
       "GM      0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0  1.0  0.0  ...   0.0  0.0   \n",
       "GOOGL   1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "HD      1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "JPM     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "KR      0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
       "MCK     0.0  1.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  1.0  ...   0.0  0.0   \n",
       "MSFT    1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "PCAR    0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...   1.0  0.0   \n",
       "PSX     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "T       0.0  0.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  1.0  ...   0.0  0.0   \n",
       "UNH     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "UNP     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "VZ      1.0  0.0   1.0  1.0  0.0  0.0   1.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
       "WBA     0.0  0.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  0.0  ...   0.0  0.0   \n",
       "WFC     0.0  1.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  1.0  ...   0.0  0.0   \n",
       "WMT     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  0.0  0.0  ...   0.0  1.0   \n",
       "XOM     0.0  0.0   0.0  0.0  0.0  1.0   0.0  0.0  0.0  1.0  ...   0.0  0.0   \n",
       "\n",
       "         T  UNH  UNP   VZ  WBA  WFC  WMT  XOM  \n",
       "AAPL   0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "ABC    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "AMZN   0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "BA     0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "BAC    0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "CAH    1.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  \n",
       "COST   0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "CVS    1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  \n",
       "CVX    0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "F      1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "GE     1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  \n",
       "GM     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "GOOGL  0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "HD     0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "JPM    0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "KR     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "MCK    1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "MSFT   0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "PCAR   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "PSX    0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "T      1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "UNH    0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "UNP    0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "VZ     0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "WBA    0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  \n",
       "WFC    0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  \n",
       "WMT    0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "XOM    0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  \n",
       "\n",
       "[28 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s_transpose_pearson[df_s_transpose_pearson >= 0.5] = 1\n",
    "df_s_transpose_pearson[df_s_transpose_pearson < 0.5] = 0\n",
    "df_s_transpose_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>CAH</th>\n",
       "      <th>COST</th>\n",
       "      <th>CVS</th>\n",
       "      <th>CVX</th>\n",
       "      <th>F</th>\n",
       "      <th>...</th>\n",
       "      <th>PCAR</th>\n",
       "      <th>PSX</th>\n",
       "      <th>T</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COST</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVX</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPM</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCAR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSX</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNH</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNP</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VZ</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WFC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMT</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAPL  ABC  AMZN   BA  BAC  CAH  COST  CVS  CVX    F  ...  PCAR  PSX  \\\n",
       "AAPL    0.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  0.0  0.0  ...   0.0  1.0   \n",
       "ABC     0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
       "AMZN    1.0  0.0   0.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "BA      1.0  0.0   1.0  0.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "BAC     1.0  0.0   1.0  1.0  0.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "CAH     0.0  0.0   0.0  0.0  0.0  0.0   0.0  1.0  0.0  1.0  ...   0.0  0.0   \n",
       "COST    1.0  0.0   1.0  1.0  1.0  0.0   0.0  0.0  0.0  0.0  ...   0.0  1.0   \n",
       "CVS     0.0  0.0   0.0  0.0  0.0  1.0   0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
       "CVX     0.0  0.0   1.0  1.0  1.0  0.0   0.0  0.0  0.0  0.0  ...   0.0  1.0   \n",
       "F       0.0  0.0   0.0  0.0  0.0  1.0   0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
       "GE      0.0  0.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  1.0  ...   0.0  0.0   \n",
       "GM      0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0  1.0  0.0  ...   0.0  0.0   \n",
       "GOOGL   1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "HD      1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "JPM     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "KR      0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
       "MCK     0.0  1.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  1.0  ...   0.0  0.0   \n",
       "MSFT    1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "PCAR    0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
       "PSX     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  0.0   \n",
       "T       0.0  0.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  1.0  ...   0.0  0.0   \n",
       "UNH     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "UNP     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  1.0  0.0  ...   0.0  1.0   \n",
       "VZ      1.0  0.0   1.0  1.0  0.0  0.0   1.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
       "WBA     0.0  0.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  0.0  ...   0.0  0.0   \n",
       "WFC     0.0  1.0   0.0  0.0  0.0  1.0   0.0  1.0  0.0  1.0  ...   0.0  0.0   \n",
       "WMT     1.0  0.0   1.0  1.0  1.0  0.0   1.0  0.0  0.0  0.0  ...   0.0  1.0   \n",
       "XOM     0.0  0.0   0.0  0.0  0.0  1.0   0.0  0.0  0.0  1.0  ...   0.0  0.0   \n",
       "\n",
       "         T  UNH  UNP   VZ  WBA  WFC  WMT  XOM  \n",
       "AAPL   0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "ABC    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "AMZN   0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "BA     0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "BAC    0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "CAH    1.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  \n",
       "COST   0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "CVS    1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  \n",
       "CVX    0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "F      1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "GE     1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  \n",
       "GM     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "GOOGL  0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "HD     0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "JPM    0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "KR     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "MCK    1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "MSFT   0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "PCAR   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "PSX    0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "T      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "UNH    0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  \n",
       "UNP    0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "VZ     0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "WBA    0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "WFC    0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  \n",
       "WMT    0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  \n",
       "XOM    0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  \n",
       "\n",
       "[28 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the diagonal element to be zero. No self loop/edge\n",
    "import numpy as np\n",
    "np.fill_diagonal(df_s_transpose_pearson.values, 0)\n",
    "df_s_transpose_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mSTOP\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d51JMw1Wx21C"
   },
   "source": [
    "Create and visualize the Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UogyyrI1vZnU"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "Graph_pearson = nx.Graph(df_s_transpose_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 1401,
     "status": "ok",
     "timestamp": 1678154405299,
     "user": {
      "displayName": "Sayed Ahmed",
      "userId": "06810739430240035128"
     },
     "user_tz": 300
    },
    "id": "ejVAFZo2wPdk",
    "outputId": "c4cbe487-95c7-49d1-ed3b-67a38c446264"
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(Graph_pearson, pos = nx.circular_layout( Graph_pearson ), node_color = 'r', edge_color = 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s_transpose.corr(method = 'pearson', numeric_only = True)\n",
    "#df_s_transpose[[{1,2,3}]]\n",
    "\n",
    "df_s_transpose.iloc[:, 0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s_pearson_train = df_s_transpose.iloc[:, 0:15]\n",
    "df_s_transpose_pearson_train = df_s_pearson_train.corr(method = 'pearson', numeric_only = True)\n",
    "np.fill_diagonal(df_s_transpose_pearson_train.values, 0)\n",
    "\n",
    "df_s_transpose_pearson_train[df_s_transpose_pearson_train >= 0.5] = 1\n",
    "df_s_transpose_pearson_train[df_s_transpose_pearson_train < 0.5] = 0\n",
    "df_s_transpose_pearson_train\n",
    "\n",
    "df_s_transpose_pearson_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s_pearson_test = df_s_transpose.iloc[:, 15:23]\n",
    "df_s_transpose_pearson_test = df_s_pearson_test.corr(method = 'pearson', numeric_only = True)\n",
    "np.fill_diagonal(df_s_transpose_pearson_test.values, 0)\n",
    "\n",
    "df_s_transpose_pearson_train[df_s_transpose_pearson_test >= 0.5] = 1\n",
    "df_s_transpose_pearson_train[df_s_transpose_pearson_test < 0.5] = 0\n",
    "df_s_transpose_pearson_test\n",
    "\n",
    "\n",
    "df_s_pearson_validation = df_s_transpose.iloc[:, 23:]\n",
    "df_s_transpose_pearson_validation = df_s_pearson_validation.corr(method = 'pearson', numeric_only = True)\n",
    "np.fill_diagonal(df_s_transpose_pearson_validation.values, 0)\n",
    "df_s_transpose_pearson_validation\n",
    "\n",
    "df_s_transpose_pearson_validation[df_s_transpose_pearson_validation >= 0.5] = 1\n",
    "df_s_transpose_pearson_validation[df_s_transpose_pearson_validation < 0.5] = 0\n",
    "df_s_transpose_pearson_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_pearson_train = nx.Graph(df_s_transpose_pearson_train)\n",
    "graph_pearson_test = nx.Graph(df_s_transpose_pearson_test)\n",
    "graph_pearson_validation = nx.Graph(df_s_transpose_pearson_validation)\n",
    "\n",
    "\n",
    "nx.draw_networkx(graph_pearson_train, pos = nx.circular_layout( graph_pearson_train ), node_color = 'r', edge_color = 'b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s_pearson_train.corr(numeric_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(graph_pearson_test, pos = nx.circular_layout( graph_pearson_test ), node_color = 'r', edge_color = 'b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(graph_pearson_validation, pos = nx.circular_layout( graph_pearson_validation ), node_color = 'r', edge_color = 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "altlF1cynQhs"
   },
   "source": [
    "# Create GCN layer. Pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all stocks = nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improvement: make sure only stocks/nodes that are in the graph are taken\n",
    "all_stock_nodes = df_s_transpose_pearson.index.to_list()\n",
    "all_stock_nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all edges between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = [];\n",
    "target = [];\n",
    "edge_feature = [];\n",
    "\n",
    "for aStock in all_stock_nodes:\n",
    "    for anotherStock in all_stock_nodes:\n",
    "        if df_s_transpose_pearson[aStock][anotherStock] > 0:\n",
    "            #print(df_s_transpose_pearson[aStock][anotherStock])\n",
    "            source.append(aStock)\n",
    "            target.append(anotherStock)\n",
    "            edge_feature.append(1)\n",
    "\n",
    "# edge feature is not required except for news based graph\n",
    "source, target, edge_feature            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSource = [];\n",
    "trainTarget = [];\n",
    "trainEdge_feature = [];\n",
    "trainNodeList = df_s_transpose_pearson_train.index.to_list();\n",
    "\n",
    "testSource = [];\n",
    "testTarget = [];\n",
    "testEdge_feature = [];\n",
    "testNodeList = df_s_transpose_pearson_test.index.to_list();\n",
    "\n",
    "\n",
    "validationSource = [];\n",
    "validationTarget = [];\n",
    "validationEdge_feature = [];\n",
    "validationNodeList = df_s_transpose_pearson_validation.index.to_list();\n",
    "\n",
    "for aStock in trainNodeList:\n",
    "    for anotherStock in trainNodeList:        \n",
    "        if df_s_transpose_pearson_train[aStock][anotherStock] > 0:\n",
    "            #print(df_s_transpose_pearson[aStock][anotherStock])\n",
    "            trainSource.append(aStock)\n",
    "            trainTarget.append(anotherStock)\n",
    "            trainEdge_feature.append(1)\n",
    "                \n",
    "                \n",
    "for aStock in testNodeList:\n",
    "    for anotherStock in testNodeList:        \n",
    "        if df_s_transpose_pearson_test[aStock][anotherStock] > 0:\n",
    "            #print(df_s_transpose_pearson[aStock][anotherStock])\n",
    "            testSource.append(aStock)\n",
    "            testTarget.append(anotherStock)\n",
    "            testEdge_feature.append(1)\n",
    "\n",
    "for aStock in validationNodeList:\n",
    "    for anotherStock in validationNodeList:                    \n",
    "        if df_s_transpose_pearson_validation[aStock][anotherStock] > 0:\n",
    "            # print(df_s_transpose_pearson[aStock][anotherStock])\n",
    "            validationSource.append(aStock)\n",
    "            validationTarget.append(anotherStock)\n",
    "            validationEdge_feature.append(1)\n",
    "                        \n",
    "# edge feature is not required except for news based graph\n",
    "trainSource, trainTarget, trainEdge_feature\n",
    "testSource, testTarget, testEdge_feature\n",
    "validationSource, validationTarget, validationEdge_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create variables to create stellar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stellargraph.readthedocs.io/en/stable/demos/basics/loading-pandas.html\n",
    "pearson_edges = pd.DataFrame(\n",
    "    {\"source\": source, \"target\": target}\n",
    ")\n",
    "\n",
    "pearson_edges_data = pd.DataFrame(\n",
    "    {\"source\": source, \"target\": target, \"edge_feature\": edge_feature}\n",
    ")\n",
    "\n",
    "\n",
    "# https://stellargraph.readthedocs.io/en/stable/demos/basics/loading-pandas.html\n",
    "pearson_edges_train = pd.DataFrame(\n",
    "    {\"source\": trainSource, \"target\": trainTarget}\n",
    ")\n",
    "\n",
    "pearson_edges_data_train = pd.DataFrame(\n",
    "    {\"source\": trainSource, \"target\": trainTarget, \"edge_feature\": trainEdge_feature}\n",
    ")\n",
    "\n",
    "pearson_edges_test = pd.DataFrame(\n",
    "    {\"source\": testSource, \"target\": testTarget}\n",
    ")\n",
    "\n",
    "pearson_edges_data_test = pd.DataFrame(\n",
    "    {\"source\": testSource, \"target\": testTarget, \"edge_feature\": testEdge_feature}\n",
    ")\n",
    "\n",
    "\n",
    "pearson_edges_validation = pd.DataFrame(\n",
    "    {\"source\": validationSource, \"target\": validationTarget}\n",
    ")\n",
    "\n",
    "\n",
    "pearson_edges[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Have the time series data as part of the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure the Feature Matrix so that it can be passed to the GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s_transpose_feature = df_s_transpose.reset_index(drop = True, inplace = False)\n",
    "# df_s_transpose_feature =  df_s_transpose_feature.values.tolist()\n",
    "# print(df_s_transpose_feature.values.tolist())\n",
    "#df_s_transpose_feature['WY'].values\n",
    "df_s_transpose_feature['AAPL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring/assign data to nodes\n",
    "node_Data = [];\n",
    "for x in all_stock_nodes:\n",
    "    node_Data.append( df_s_transpose_feature[x].values)\n",
    "    \n",
    "    \n",
    "node_Data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert node data variable into a dataframe so that the data structure is compatible with graph NN\n",
    "pearson_graph_node_data = pd.DataFrame(node_Data, index = all_stock_nodes)\n",
    "pearson_graph_node_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_Data[14:15], \n",
    "len(validationNodeList)\n",
    "len(testNodeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert node data variable into a dataframe so that the data structure is compatible with graph NN\n",
    "pearson_graph_node_data_train = pd.DataFrame(node_Data[0:14], index = trainNodeList)\n",
    "pearson_graph_node_data_train.head()\n",
    "\n",
    "pearson_graph_node_data_test = pd.DataFrame(node_Data[15:23], index = testNodeList)\n",
    "pearson_graph_node_data_test.head()\n",
    "\n",
    "pearson_graph_node_data_validation = pd.DataFrame(node_Data[22:30], index = validationNodeList)\n",
    "pearson_graph_node_data_validation.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph (stellar) with features as part of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_graph_with_node_features = StellarGraph(pearson_graph_node_data, edges = pearson_edges, node_type_default = \"corner\", edge_type_default = \"line\")\n",
    "print(pearson_graph_with_node_features.info())\n",
    "\n",
    "# train nodes\n",
    "pearson_train_graph_with_node_features = StellarGraph(pearson_graph_node_data_train, edges = pearson_edges_train, node_type_default = \"corner\", edge_type_default = \"line\")\n",
    "print(pearson_train_graph_with_node_features.info())\n",
    "\n",
    "\n",
    "pearson_test_graph_with_node_features = StellarGraph(pearson_graph_node_data_test, edges = pearson_edges_test, node_type_default = \"corner\", edge_type_default = \"line\")\n",
    "print(pearson_test_graph_with_node_features.info())\n",
    "\n",
    "pearson_validation_graph_with_node_features = StellarGraph(pearson_graph_node_data_validation, edges = pearson_edges_validation, node_type_default = \"corner\", edge_type_default = \"line\")\n",
    "print(pearson_validation_graph_with_node_features.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting everything for DeepGraphCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_graph_node_data.iloc[0:15, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n",
    "pearson_train_graph_with_node_features = StellarGraph(pearson_graph_node_data.iloc[0:15, :], edges = pearson_edges.iloc[0:15, :], node_type_default = \"corner\", edge_type_default = \"line\")\n",
    "print(pearson_train_graph_with_node_features.info())\n",
    "\n",
    "\n",
    "'''\n",
    "pearson_train_graph_with_node_features = StellarGraph(pearson_graph_node_data[:10], edges = pearson_edges[:10], node_type_default = \"corner\", edge_type_default = \"line\")\n",
    "print(pearson_train_graph_with_node_features.info())\n",
    "\n",
    "pearson_train_graph_with_node_features = StellarGraph(pearson_graph_node_data[:10], edges = pearson_edges[:10], node_type_default = \"corner\", edge_type_default = \"line\")\n",
    "print(pearson_train_graph_with_node_features.info())\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = list()\n",
    "#graphs.append(pearson_graph_with_node_features)\n",
    "graphs.append(pearson_train_graph_with_node_features)\n",
    "graphs.append(pearson_test_graph_with_node_features)\n",
    "graphs.append(pearson_validation_graph_with_node_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(\n",
    "    [(g.number_of_nodes(), g.number_of_edges()) for g in graphs],\n",
    "    columns=[\"nodes\", \"edges\"],\n",
    ")\n",
    "summary.describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_labels = all_stock_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "#generator = FullBatchNodeGenerator(pearson_graph_with_node_features, method = \"gcn\") # , sparse = False\n",
    "#vars(generator)\n",
    "\n",
    "generator = PaddedGraphGenerator( graphs = graphs)\n",
    "# generator = PaddedGraphGenerator( pearson_graph_with_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects, test_subjects = model_selection.train_test_split(\n",
    "    pearson_graph_node_data \n",
    ")\n",
    "\n",
    "val_subjects, test_subjects_step_2 = model_selection.train_test_split(\n",
    "    test_subjects \n",
    ")\n",
    "\n",
    "#, train_size = 500, test_size = None, stratify = test_subjects\n",
    "\n",
    "train_subjects.shape, test_subjects.shape, val_subjects.shape, test_subjects_step_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = train_subjects; \n",
    "val_targets = val_subjects; \n",
    "test_targets = test_subjects; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator.flow(train_subjects.index, train_targets)\n",
    "test_gen = generator.flow(test_subjects.index, test_targets)\n",
    "valid_gen = generator.flow(val_subjects.index, val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "train_subjects.index, \n",
    "train_targets[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data size\n",
    "unit_count = train_subjects.shape[0]\n",
    "unit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard coded size adjustments\n",
    "test_subjects_ = test_subjects[:len(val_subjects)]\n",
    "\n",
    "val_gen = generator.flow(val_subjects.index, test_subjects_)\n",
    "#train_gen[1], val_gen[1]\n",
    "#val_gen[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model for all of the approaches utilized in this file\n",
    "# Model for Pearson, Spearman, Kendal Tau, Financial News Based prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hard coded size adjustments\n",
    "test_subjects_adjusted = test_subjects[:len(val_subjects)]\n",
    "\n",
    "val_gen = generator.flow(val_subjects.index, test_subjects_adjusted)\n",
    "#train_gen[1], val_gen[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models : DeepGraph CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_to_test = 2\n",
    "patience_to_test = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with DeepGraphCNN\n",
    "# https://stellargraph.readthedocs.io/en/latest/demos/graph-classification/dgcnn-graph-classification.html\n",
    "\n",
    "\n",
    "# unit_count = 35\n",
    "k =   unit_count # the number of rows for the output tensor\n",
    "layer_sizes = [32, 32, 32, 1]\n",
    "\n",
    "dgcnn_model = DeepGraphCNN(\n",
    "    layer_sizes = layer_sizes,\n",
    "    activations = [\"tanh\", \"tanh\", \"tanh\", \"tanh\"],\n",
    "    k = k,\n",
    "    bias = False,\n",
    "    generator = generator,\n",
    ")\n",
    "x_inp, x_out = dgcnn_model.in_out_tensors()\n",
    "\n",
    "#print(graphs[0].info())\n",
    "x_inp, x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dgcnn_model.summary()\n",
    "\n",
    "# print(dgcnn_model.info())\n",
    "dgcnn_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = Conv1D(filters = 16, kernel_size = sum(layer_sizes), strides = sum(layer_sizes))(x_out)\n",
    "x_out = MaxPool1D(pool_size=2)(x_out)\n",
    "\n",
    "x_out = Conv1D(filters = 32, kernel_size = 5, strides = 1)(x_out)\n",
    "\n",
    "x_out = Flatten()(x_out)\n",
    "\n",
    "x_out = Dense(units = 128, activation = \"relu\")(x_out)\n",
    "x_out = Dropout(rate = 0.5)(x_out)\n",
    "\n",
    "#predictions = Dense(units=1, activation=\"linear\")(x_out)\n",
    "predictions = layers.Dense(units = train_targets.shape[1], activation = \"linear\")(x_out)\n",
    "#predictions = layers.Dense(units = 1, activation = \"linear\")(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=x_inp, outputs=predictions)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'mean_absolute_error', \n",
    "    optimizer = optimizers.Adam( learning_rate = 0.1), \n",
    "    metrics = ['mean_squared_error']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start using model.fit from 1st and 2nd models **********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es_callback = EarlyStopping(\n",
    "    monitor = \"val_mean_squared_error\", \n",
    "    patience = patience_to_test, \n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fit is from 2nd model\n",
    "history = model.fit( train_gen_data, epochs = epochs_to_test, validation_data = data_valid, verbose = 1,    \n",
    "    # shuffling = true means shuffling the whole graph\n",
    "    shuffle = False , callbacks = [es_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End using model.fit from 1st and 2nd models ************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_list = set(list(all_stock_nodes))\n",
    "keys = [x for x in range(len(initial_list))]\n",
    "new_dict = dict(zip(keys, initial_list)) \n",
    "\n",
    "[ list(new_dict.values()).index(item) for item in  train_subjects.index]\n",
    "\n",
    "#dict((item['id'], item) for item in initial_list)\n",
    "keys, new_dict, train_gen\n",
    "train_gen_node_id_list = [ list(new_dict.values()).index(item) for item in  train_subjects.index]\n",
    "test_gen_node_id_list = [ list(new_dict.values()).index(item) for item in  test_targets.index]\n",
    "train_gen_node_id_list[:5], test_gen_node_id_list[:], keys[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard coded size adjustments\n",
    "test_subjects_ = test_subjects[:len(val_subjects)]\n",
    "\n",
    "val_gen = generator.flow(val_subjects.index, test_subjects_)\n",
    "#train_gen[1], val_gen[1]\n",
    "#val_gen[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worked\n",
    "train_gen = generator.flow(\n",
    "    #list(train_subjects.index),\n",
    "    #train_gen_node_id_list,\n",
    "    [0],\n",
    "    targets = [0], #train_subjects.values,\n",
    "    batch_size = 1,\n",
    "    symmetric_normalization = False,\n",
    ")\n",
    "\n",
    "test_gen = generator.flow(\n",
    "    #list(test_targets.index),\n",
    "    #test_gen_node_id_list,\n",
    "    [1],\n",
    "    targets = [1],#test_targets.values,\n",
    "    batch_size = 1,\n",
    "    symmetric_normalization = False,\n",
    ")\n",
    "\n",
    "\n",
    "all_gen = generator.flow(\n",
    "    #list(test_targets.index),\n",
    "    #test_gen_node_id_list,\n",
    "    [0],\n",
    "    targets=[0],#test_targets.values,\n",
    "    batch_size=1,\n",
    "    symmetric_normalization=False,\n",
    ")\n",
    "\n",
    "data_valid = val_gen #[:1][:4];\n",
    "train_gen_data = train_gen #[:1][:4];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen[0], \n",
    "#train_subjects\n",
    "#train_subjects.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment\n",
    "train_gen = generator.flow(\n",
    "    #list(train_subjects.index),\n",
    "    train_gen_node_id_list,\n",
    "    #[0],\n",
    "    targets = train_subjects[0],\n",
    "    batch_size = 1,\n",
    "    symmetric_normalization = False,\n",
    ")\n",
    "\n",
    "test_gen = generator.flow(\n",
    "    #list(test_targets.index),\n",
    "    test_gen_node_id_list,\n",
    "    #[0],\n",
    "    targets = test_targets,\n",
    "    batch_size = 1,\n",
    "    symmetric_normalization = False,\n",
    ")\n",
    "\n",
    "'''\n",
    "all_gen = generator.flow(\n",
    "    #list(test_targets.index),\n",
    "    #test_gen_node_id_list,\n",
    "    [0],\n",
    "    targets=[0],#test_targets.values,\n",
    "    batch_size=1,\n",
    "    symmetric_normalization=False,\n",
    ")\n",
    "'''\n",
    "\n",
    "data_valid = val_gen #[:1][:4];\n",
    "train_gen_data = train_gen #[:1][:4];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(train_gen), \n",
    "#train_subjects\n",
    "#train_subjects.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, data_valid, train_gen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stellargraph.readthedocs.io/en/stable/demos/graph-classification/dgcnn-graph-classification.html?highlight=cnn\n",
    "# with DeepGraphCNN model.fit\n",
    "history = model.fit(\n",
    "    train_gen, epochs = epochs_to_test, verbose = 1, validation_data = test_gen, shuffle = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es_callback = EarlyStopping(monitor = \"val_mean_squared_error\", patience = 50, restore_best_weights = True)\n",
    "\n",
    "\n",
    "'''\n",
    "history = model.fit( train_gen_data, epochs = 100, validation_data = data_valid, verbose = 1,    \n",
    "    # shuffling = true means shuffling the whole graph\n",
    "    shuffle = True, callbacks = [es_callback],\n",
    ")\n",
    "'''\n",
    "\n",
    "history = model.fit (\n",
    "    train_gen, epochs=epochs, verbose=1, validation_data=test_gen, shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sg.utils.plot_history(history)\n",
    "\n",
    "# [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss functions: https://keras.io/api/losses/\n",
    "\n",
    "model = Model(\n",
    "    inputs = x_inp, outputs = predictions)\n",
    "\n",
    "'''\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.1),\n",
    "    loss=losses.MeanSquaredError(),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "# REF: https://stackoverflow.com/questions/57301698/how-to-change-a-learning-rate-for-adam-in-tf2\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay\n",
    "train_steps = 1000\n",
    "lr_fn = optimizers.schedules.PolynomialDecay(1e-3, train_steps, 1e-5, 2)\n",
    "\n",
    "# https://keras.io/api/metrics/\n",
    "model.compile(\n",
    "    loss = 'mean_absolute_error', \n",
    "    optimizer = optimizers.Adam( lr_fn ),\n",
    "    # metrics = ['mean_squared_error']\n",
    "    metrics=['mse', 'mae', 'mape']\n",
    ")\n",
    "'''\n",
    "\n",
    "# 1st block\n",
    "# mape: https://towardsdatascience.com/choosing-the-correct-error-metric-mape-vs-smape-5328dec53fac\n",
    "model.compile( \n",
    "    loss = 'mean_absolute_error', \n",
    "    optimizer = optimizers.Adam(learning_rate = 0.015), \n",
    "    #optimizer = optimizers.Adam(lr_fn), \n",
    "    # metrics=['mean_squared_error']\n",
    "    metrics=['mean_squared_error', 'mae', 'mape']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(x_inp), predictions.shape, print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(val_subjects)\n",
    "test_subjects_ = test_subjects[:len(val_subjects)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hard coded size adjustments\n",
    "test_subjects_ = test_subjects[:len(val_subjects)]\n",
    "\n",
    "val_gen = generator.flow(val_subjects.index, test_subjects_)\n",
    "#train_gen[1], val_gen[1]\n",
    "val_gen[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_gen[:1][:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# type(train_gen_data), type(data_valid), type(x_inp), type(x_out) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "es_callback = EarlyStopping(\n",
    "    monitor = \"val_mean_squared_error\", \n",
    "    patience = patience_to_test, \n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit( train_gen_data, epochs = epochs_to_test, validation_data = data_valid, verbose = 2,    \n",
    "    # shuffling = true means shuffling the whole graph\n",
    "    shuffle = False, callbacks = [es_callback],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subjects, \n",
    "test_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_gen = generator.flow(test_subjects.index, test_targets)\n",
    "test_metrics = model.evaluate(test_gen)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(columns=['Method', 'Loss', 'MSE'])#, 'MAE', 'MAPE'])\n",
    "\n",
    "temp = list()\n",
    "temp.append('GCN-Pearson');\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    # print(val)\n",
    "    temp.append(val)\n",
    "\n",
    "print(temp)\n",
    "df_metrics.loc[1] = temp\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the predicted prices by the Model\n",
    "\n",
    "At this point, I still need to make sense of what GCN ( and CNN) combination + MLP is predicting. \n",
    "I am just displaying the output. \n",
    "It appears that price is predicted for each timestamp (day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = pearson_graph_node_data.index;\n",
    "all_gen = generator.flow(all_nodes)\n",
    "all_predictions = model.predict(test_gen)\n",
    "all_predictions = model.predict(train_gen)\n",
    "\n",
    "all_nodes, all_predictions, all_predictions.shape, pearson_graph_node_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\n",
    "model.predict(\n",
    "    all_gen,\n",
    "    batch_size = None,\n",
    "    verbose = 2,\n",
    "    steps = None,\n",
    "    callbacks = None,\n",
    "    max_queue_size = 10,\n",
    "    workers = 1,\n",
    "    use_multiprocessing = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_predictions = model.predict(all_nodes)\n",
    "\n",
    "# all_predictions, all_predictions.shape, pearson_graph_node_data.shape\n",
    "vars(all_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_graph_node_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(all_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen[:1][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "****************************************************\n",
    "STOP because we are testing a new model\n",
    "****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPEARMAN ***************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman\n",
    "\n",
    "df_s_transpose_spearman = df_s_transpose.corr(method = 'spearman', numeric_only = True)\n",
    "df_s_transpose_spearman\n",
    "\n",
    "\n",
    "# # Pearson Correlation Coefficient based Adjacency Graph Matrix\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "df_s_transpose_spearman[df_s_transpose_spearman >= 0.4] = 1\n",
    "df_s_transpose_spearman[df_s_transpose_spearman < 0.4] = 0\n",
    "df_s_transpose_spearman\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "# make the diagonal element to be zero. No self loop\n",
    "import numpy as np\n",
    "np.fill_diagonal(df_s_transpose_spearman.values, 0)\n",
    "df_s_transpose_spearman\n",
    "\n",
    "\n",
    "# Create and visualize the Graphs\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "Graph_spearman = nx.Graph(df_s_transpose_spearman)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "nx.draw_networkx(Graph_spearman, pos=nx.circular_layout(Graph_spearman), node_color='r', edge_color='b')\n",
    "\n",
    "\n",
    "# # Create GCN layer. Graph_spearman\n",
    "\n",
    "# # Find all stocks = nodes\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "# improvement: make sure only stocks/nodes that are in the graph are taken\n",
    "all_stock_nodes = df_s_transpose_spearman.index.to_list()\n",
    "all_stock_nodes\n",
    "\n",
    "\n",
    "# # Find all edges between nodes\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "source = [];\n",
    "target = [];\n",
    "edge_feature = [];\n",
    "\n",
    "for aStock in all_stock_nodes:\n",
    "    for anotherStock in all_stock_nodes:\n",
    "        if df_s_transpose_spearman[aStock][anotherStock] > 0:\n",
    "            #print(df_s_transpose_spearman[aStock][anotherStock])\n",
    "            source.append(aStock)\n",
    "            target.append(anotherStock)\n",
    "            edge_feature.append(1)\n",
    "            \n",
    "source, target, edge_feature            \n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "# https://stellargraph.readthedocs.io/en/stable/demos/basics/loading-pandas.html\n",
    "spearman_edges = pd.DataFrame(\n",
    "    {\"source\": source, \"target\": target}\n",
    ")\n",
    "\n",
    "spearman_edges_data = pd.DataFrame(\n",
    "    {\"source\": source, \"target\": target, \"edge_feature\": edge_feature}\n",
    ")\n",
    "\n",
    "\n",
    "spearman_edges[:10]\n",
    "\n",
    "\n",
    "# # Graph with No Feature Data, No node data, only edges\n",
    "\n",
    "# spearman_graph = StellarGraph(edges = spearman_edges, node_type_default=\"corner\", edge_type_default=\"line\")\n",
    "# #spearman_graph = StellarGraph(nodes = all_stock_nodes, edges = spearman_edges)\n",
    "# # graph = sg.StellarGraph(all_stock_nodes, square_edges)\n",
    "# print(spearman_graph.info())\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "# Trying to have the time series data as part of the nodes\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "df_s_transpose\n",
    "\n",
    "\n",
    "# # Structure the Feature Matrix so that it can be passed to the GCN\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "df_s_transpose_feature = df_s_transpose.reset_index(drop = True, inplace = False)\n",
    "# df_s_transpose_feature =  df_s_transpose_feature.values.tolist()\n",
    "# print(df_s_transpose_feature.values.tolist())\n",
    "#df_s_transpose_feature['WY'].values\n",
    "df_s_transpose_feature['AAPL'].values\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "node_Data = [];\n",
    "for x in all_stock_nodes:\n",
    "    node_Data.append( df_s_transpose_feature[x].values)\n",
    "    \n",
    "    \n",
    "node_Data    \n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "spearman_graph_node_data = pd.DataFrame(node_Data, index = all_stock_nodes)\n",
    "spearman_graph_node_data\n",
    "\n",
    "\n",
    "# # Graph with feature as part of Nodes\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "spearman_graph_with_node_features = StellarGraph(spearman_graph_node_data, edges = spearman_edges, node_type_default = \"corner\", edge_type_default = \"line\")\n",
    "print(pearson_graph_with_node_features.info())\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "# Generator\n",
    "generator = FullBatchNodeGenerator(spearman_graph_with_node_features, method = \"gcn\") # , sparse = False\n",
    "vars(generator)\n",
    "\n",
    "\n",
    "# # Train Test Split\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "train_subjects, test_subjects = model_selection.train_test_split(\n",
    "    spearman_graph_node_data #, train_size = 6, test_size = 4\n",
    ")\n",
    "# , train_size=6, test_size=None, stratify=pearson_graph_node_data\n",
    "\n",
    "val_subjects, test_subjects_step_2 = model_selection.train_test_split(\n",
    "    test_subjects #, test_size = 2\n",
    ")\n",
    "\n",
    "#, train_size = 500, test_size = None, stratify = test_subjects\n",
    "\n",
    "\n",
    "train_subjects.shape, test_subjects.shape, val_subjects.shape, test_subjects_step_2.shape\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "spearman_graph_node_data\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "train_targets = train_subjects; \n",
    "val_targets = val_subjects; \n",
    "test_targets = test_subjects; \n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "train_gen = generator.flow(train_subjects.index, train_targets)\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "# debug\n",
    "train_subjects.index, \n",
    "train_targets\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "# train data size\n",
    "# it is not must to use a number like unit_count\n",
    "unit_count = train_subjects.shape[0]\n",
    "unit_count\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "'''\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "from tensorflow import keras\n",
    "\n",
    "layer_sizes = [32, 32]\n",
    "activations = [\"relu\", \"relu\"]\n",
    "'''\n",
    "\n",
    "gcn = GCN(layer_sizes = layer_sizes, activations = activations, generator = generator) #, dropout = 0.5\n",
    "x_inp, x_out = gcn.in_out_tensors()\n",
    "\n",
    "# MLP -- Regression\n",
    "predictions = layers.Dense(units = train_targets.shape[1], activation = \"linear\")(x_out)\n",
    "\n",
    "'''\n",
    "x_out, \n",
    "x_inp, x_out\n",
    "'''\n",
    "\n",
    "# # hard coded size adjustments\n",
    "# test_subjects_adjusted = test_subjects[:len(val_subjects)]\n",
    "# \n",
    "# val_gen = generator.flow(val_subjects.index, test_subjects_adjusted)\n",
    "# # train_gen[1], val_gen[1]\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "# Models Although this code could be removed as Model is defined earlier and the same model/architecture is used by all approaches\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "# loss functions: https://keras.io/api/losses/\n",
    "'''\n",
    "model = Model(\n",
    "    inputs = x_inp, outputs = predictions\n",
    ")\n",
    "'''\n",
    "'''\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.1),\n",
    "    loss=losses.MeanSquaredError(),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "'''\n",
    "\n",
    "# REF: https://stackoverflow.com/questions/57301698/how-to-change-a-learning-rate-for-adam-in-tf2\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay\n",
    "# train_steps = 1000\n",
    "# lr_fn = optimizers.schedules.PolynomialDecay(1e-3, train_steps, 1e-5, 2)\n",
    "\n",
    "\n",
    "# https://keras.io/api/metrics/\n",
    "'''\n",
    "model.compile(\n",
    "    loss = 'mean_absolute_error', \n",
    "    optimizer = optimizers.Adam( lr_fn ),\n",
    "    # metrics = ['mean_squared_error']\n",
    "    metrics=['mse', 'mae', 'mape']\n",
    ")\n",
    "'''\n",
    "# 2nd block\n",
    "# mape: https://towardsdatascience.com/choosing-the-correct-error-metric-mape-vs-smape-5328dec53fac\n",
    "model.compile( \n",
    "    loss = 'mean_absolute_error', \n",
    "    optimizer = optimizers.Adam(learning_rate = 0.015), \n",
    "    #optimizer = optimizers.Adam(lr_fn), \n",
    "    # metrics=['mean_squared_error']\n",
    "    metrics=['mean_squared_error', 'mae', 'mape']\n",
    "    # metrics=[\n",
    "    #    metrics.MeanSquaredError(),\n",
    "    #    metrics.AUC(),\n",
    "    #]\n",
    ")\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "len(x_inp), predictions.shape, print(model.summary())\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "len(val_subjects)\n",
    "test_subjects_ = test_subjects[:len(val_subjects)]\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "\n",
    "# hard coded size adjustments\n",
    "test_subjects_ = test_subjects[:len(val_subjects)]\n",
    "\n",
    "val_gen = generator.flow(val_subjects.index, test_subjects_)\n",
    "#train_gen[1], val_gen[1]\n",
    "\n",
    "\n",
    "# train_gen[:1][:4]\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "'''\n",
    "#epochs_to_test = 10000\n",
    "#patience_to_test = 10000\n",
    "\n",
    "es_callback = EarlyStopping(\n",
    "    monitor = \"val_mean_squared_error\", \n",
    "    patience = patience_to_test, \n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "data_valid = val_gen #[:1][:4];\n",
    "train_gen_data = train_gen #[:1][:4];\n",
    "'''\n",
    "\n",
    "history = model.fit( train_gen_data, epochs = epochs_to_test, validation_data = data_valid, verbose = 2,    \n",
    "    # shuffling = true means shuffling the whole graph\n",
    "    shuffle = False, callbacks = [es_callback],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "val_subjects, \n",
    "test_subjects\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "test_gen = generator.flow(test_subjects.index, test_targets)\n",
    "test_metrics = model.evaluate(test_gen)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "    \n",
    "    \n",
    "#df_metrics = pd.DataFrame(columns=['Method', 'Loss', 'MSE', 'MAE', 'MAPE'])\n",
    "\n",
    "temp = list()\n",
    "temp.append('GCN-Spearman');\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    # print(val)\n",
    "    temp.append(val)\n",
    "\n",
    "print(temp)\n",
    "df_metrics.loc[2] = temp\n",
    "df_metrics\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# # Show the predicted prices by the Model\n",
    "# \n",
    "# At this point, I still need to make sense of what GCN ( and CNN) combination + MLP is predicting. \n",
    "# I am just displaying the output. \n",
    "# It appears that price is predicted for each timestamp (day)\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "all_nodes = spearman_graph_node_data.index;\n",
    "all_gen = generator.flow(all_nodes)\n",
    "all_predictions = model.predict(all_gen)\n",
    "\n",
    "all_nodes, all_predictions, all_predictions.shape, spearman_graph_node_data.shape\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\n",
    "model.predict(\n",
    "    all_gen,\n",
    "    batch_size = None,\n",
    "    verbose = 2,\n",
    "    steps = None,\n",
    "    callbacks = None,\n",
    "    max_queue_size = 10,\n",
    "    workers = 1,\n",
    "    use_multiprocessing = False\n",
    ")\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "# all_predictions = model.predict(all_nodes)\n",
    "\n",
    "# all_predictions, all_predictions.shape, spearman_graph_node_data.shape\n",
    "vars(all_gen)\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "spearman_graph_node_data\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "vars(all_gen)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "train_gen[:1][:4]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kendal Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kendall_tau\n",
    "\n",
    "df_s_transpose_kendall_tau = df_s_transpose.corr(method = 'kendall', numeric_only = True)\n",
    "df_s_transpose_kendall_tau\n",
    "\n",
    "\n",
    "# # kendall_tau Correlation Coefficient based Adjacency Graph Matrix\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "df_s_transpose_kendall_tau[df_s_transpose_kendall_tau >= 0.3] = 1\n",
    "df_s_transpose_kendall_tau[df_s_transpose_kendall_tau < 0.3] = 0\n",
    "df_s_transpose_kendall_tau\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "# make the diagonal element to be zero. No self loop\n",
    "import numpy as np\n",
    "np.fill_diagonal(df_s_transpose_kendall_tau.values, 0)\n",
    "df_s_transpose_kendall_tau\n",
    "\n",
    "\n",
    "# Create and visualize the Graphs\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "Graph_kendall_tau = nx.Graph(df_s_transpose_kendall_tau)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "nx.draw_networkx(Graph_kendall_tau, pos=nx.circular_layout(Graph_kendall_tau), node_color='r', edge_color='b')\n",
    "\n",
    "\n",
    "# # Create GCN layer. Graph_kendall_tau\n",
    "\n",
    "# # Find all stocks = nodes\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "# improvement: make sure only stocks/nodes that are in the graph are taken\n",
    "all_stock_nodes = df_s_transpose_kendall_tau.index.to_list()\n",
    "all_stock_nodes\n",
    "\n",
    "\n",
    "# # Find all edges between nodes\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "source = [];\n",
    "target = [];\n",
    "edge_feature = [];\n",
    "\n",
    "for aStock in all_stock_nodes:\n",
    "    for anotherStock in all_stock_nodes:\n",
    "        if df_s_transpose_kendall_tau[aStock][anotherStock] > 0:\n",
    "            #print(df_s_transpose_kendall_tau[aStock][anotherStock])\n",
    "            source.append(aStock)\n",
    "            target.append(anotherStock)\n",
    "            edge_feature.append(1)\n",
    "            \n",
    "source, target, edge_feature            \n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "# https://stellargraph.readthedocs.io/en/stable/demos/basics/loading-pandas.html\n",
    "kendall_tau_edges = pd.DataFrame(\n",
    "    {\"source\": source, \"target\": target}\n",
    ")\n",
    "\n",
    "kendall_tau_edges_data = pd.DataFrame(\n",
    "    {\"source\": source, \"target\": target, \"edge_feature\": edge_feature}\n",
    ")\n",
    "\n",
    "\n",
    "kendall_tau_edges[:10]\n",
    "\n",
    "\n",
    "# # Graph with No Feature Data, No node data, only edges\n",
    "\n",
    "# kendall_tau_graph = StellarGraph(edges = kendall_tau_edges, node_type_default=\"corner\", edge_type_default=\"line\")\n",
    "# #kendall_tau_graph = StellarGraph(nodes = all_stock_nodes, edges = kendall_tau_edges)\n",
    "# # graph = sg.StellarGraph(all_stock_nodes, square_edges)\n",
    "# print(kendall_tau_graph.info())\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "# Trying to have the time series data as part of the nodes\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "df_s_transpose\n",
    "\n",
    "\n",
    "# # Structure the Feature Matrix so that it can be passed to the GCN\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "df_s_transpose_feature = df_s_transpose.reset_index(drop = True, inplace = False)\n",
    "# df_s_transpose_feature =  df_s_transpose_feature.values.tolist()\n",
    "# print(df_s_transpose_feature.values.tolist())\n",
    "#df_s_transpose_feature['WY'].values\n",
    "df_s_transpose_feature['AAPL'].values\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "node_Data = [];\n",
    "for x in all_stock_nodes:\n",
    "    node_Data.append( df_s_transpose_feature[x].values)\n",
    "    \n",
    "    \n",
    "node_Data    \n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "kendall_tau_graph_node_data = pd.DataFrame(node_Data, index = all_stock_nodes)\n",
    "kendall_tau_graph_node_data\n",
    "\n",
    "\n",
    "# # Graph with feature as part of Nodes\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "kendall_tau_graph_with_node_features = StellarGraph(kendall_tau_graph_node_data, edges = kendall_tau_edges, node_type_default = \"corner\", edge_type_default = \"line\")\n",
    "print(kendall_tau_graph_with_node_features.info())\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "# Generator\n",
    "generator = FullBatchNodeGenerator(kendall_tau_graph_with_node_features, method = \"gcn\") # , sparse = False\n",
    "vars(generator)\n",
    "\n",
    "\n",
    "# # Train Test Split\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "train_subjects, test_subjects = model_selection.train_test_split(\n",
    "    kendall_tau_graph_node_data #, train_size = 6, test_size = 4\n",
    ")\n",
    "# , train_size=6, test_size=None, stratify=kendall_tau_graph_node_data\n",
    "\n",
    "val_subjects, test_subjects_step_2 = model_selection.train_test_split(\n",
    "    test_subjects #, test_size = 2\n",
    ")\n",
    "\n",
    "#, train_size = 500, test_size = None, stratify = test_subjects\n",
    "\n",
    "\n",
    "train_subjects.shape, test_subjects.shape, val_subjects.shape, test_subjects_step_2.shape\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "kendall_tau_graph_node_data\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "train_targets = train_subjects; \n",
    "val_targets = val_subjects; \n",
    "test_targets = test_subjects; \n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "train_gen = generator.flow(train_subjects.index, train_targets)\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "# debug\n",
    "train_subjects.index, \n",
    "train_targets\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "# train data size\n",
    "# it is not must to use a number like unit_count\n",
    "unit_count = train_subjects.shape[0]\n",
    "unit_count\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "'''\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "from tensorflow import keras\n",
    "\n",
    "layer_sizes = [32, 32]\n",
    "activations = [\"relu\", \"relu\"]\n",
    "'''\n",
    "gcn = GCN(layer_sizes = layer_sizes, activations = activations, generator = generator) #, dropout = 0.5\n",
    "x_inp, x_out = gcn.in_out_tensors()\n",
    "\n",
    "# MLP -- Regression\n",
    "predictions = layers.Dense(units = train_targets.shape[1], activation = \"linear\")(x_out)\n",
    "\n",
    "'''\n",
    "x_out, \n",
    "x_inp, x_out\n",
    "\n",
    "\n",
    "# # hard coded size adjustments\n",
    "# test_subjects_adjusted = test_subjects[:len(val_subjects)]\n",
    "# \n",
    "# val_gen = generator.flow(val_subjects.index, test_subjects_adjusted)\n",
    "# # train_gen[1], val_gen[1]\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "# Models\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "# loss functions: https://keras.io/api/losses/\n",
    "\n",
    "model = Model(\n",
    "    inputs = x_inp, outputs = predictions)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.1),\n",
    "    loss=losses.MeanSquaredError(),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "\n",
    "# REF: https://stackoverflow.com/questions/57301698/how-to-change-a-learning-rate-for-adam-in-tf2\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay\n",
    "train_steps = 1000\n",
    "lr_fn = optimizers.schedules.PolynomialDecay(1e-3, train_steps, 1e-5, 2)\n",
    "\n",
    "\n",
    "# https://keras.io/api/metrics/\n",
    "model.compile(\n",
    "    loss = 'mean_absolute_error', \n",
    "    optimizer = optimizers.Adam( lr_fn ),\n",
    "    # metrics = ['mean_squared_error']\n",
    "    metrics=['mse', 'mae', 'mape']\n",
    ")\n",
    "\n",
    "'''\n",
    "\n",
    "# 3rd block\n",
    "# mape: https://towardsdatascience.com/choosing-the-correct-error-metric-mape-vs-smape-5328dec53fac\n",
    "model.compile( \n",
    "    loss = 'mean_absolute_error', \n",
    "    optimizer = optimizers.Adam(learning_rate = 0.015), \n",
    "    #optimizer = optimizers.Adam(lr_fn), \n",
    "    # metrics=['mean_squared_error']\n",
    "    metrics=['mean_squared_error', 'mae', 'mape']\n",
    "    # metrics=[\n",
    "    #    metrics.MeanSquaredError(),\n",
    "    #    metrics.AUC(),\n",
    "    #]\n",
    ")\n",
    "\n",
    "\n",
    "len(x_inp), predictions.shape, print(model.summary())\n",
    "\n",
    "len(val_subjects)\n",
    "test_subjects_ = test_subjects[:len(val_subjects)]\n",
    "\n",
    "# hard coded size adjustments\n",
    "test_subjects_ = test_subjects[:len(val_subjects)]\n",
    "\n",
    "val_gen = generator.flow(val_subjects.index, test_subjects_)\n",
    "#train_gen[1], val_gen[1]\n",
    "\n",
    "\n",
    "# train_gen[:1][:4]\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "'''\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es_callback = EarlyStopping(\n",
    "    monitor = \"val_mean_squared_error\", \n",
    "    patience = patience_to_test, \n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "data_valid = val_gen #[:1][:4];\n",
    "train_gen_data = train_gen #[:1][:4];\n",
    "'''\n",
    "\n",
    "history = model.fit( train_gen_data, epochs = epochs_to_test, validation_data = data_valid, verbose = 2,    \n",
    "    # shuffling = true means shuffling the whole graph\n",
    "    shuffle = False, callbacks = [es_callback],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(Graph_kendall_tau, pos=nx.circular_layout(Graph_kendall_tau), node_color='r', edge_color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "val_subjects, \n",
    "test_subjects\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "test_gen = generator.flow(test_subjects.index, test_targets)\n",
    "test_metrics = model.evaluate(test_gen)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "    \n",
    "\n",
    "\n",
    "# # Show the predicted prices by the Model\n",
    "# \n",
    "# At this point, I still need to make sense of what GCN ( and CNN) combination + MLP is predicting. \n",
    "# I am just displaying the output. \n",
    "# It appears that price is predicted for each timestamp (day)\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "all_nodes = kendall_tau_graph_node_data.index;\n",
    "all_gen = generator.flow(all_nodes)\n",
    "all_predictions = model.predict(all_gen)\n",
    "\n",
    "all_nodes, all_predictions, all_predictions.shape, kendall_tau_graph_node_data.shape\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\n",
    "model.predict(\n",
    "    all_gen,\n",
    "    batch_size = None,\n",
    "    verbose = 2,\n",
    "    steps = None,\n",
    "    callbacks = None,\n",
    "    max_queue_size = 10,\n",
    "    workers = 1,\n",
    "    use_multiprocessing = False\n",
    ")\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "# all_predictions = model.predict(all_nodes)\n",
    "\n",
    "# all_predictions, all_predictions.shape, kendall_tau_graph_node_data.shape\n",
    "vars(all_gen)\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "kendall_tau_graph_node_data\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "vars(all_gen)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "train_gen[:1][:4]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_metrics = pd.DataFrame(columns=['Method', 'Loss', 'MSE', 'MAE', 'MAPE'])\n",
    "# df_metrics = pd.DataFrame(columns=['Method', 'Loss', 'MSE', 'MAE', 'MAPE'])\n",
    "\n",
    "temp = list()\n",
    "temp.append('GCN-Kendall');\n",
    "for name, val in zip(model.metrics_names, test_metrics):    \n",
    "    temp.append(val)\n",
    "\n",
    "print(temp)\n",
    "df_metrics.loc[3] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "df_metrics_plot = df_metrics[['Loss', 'MSE', 'MAE', 'MAPE']]\n",
    "\n",
    "#temp = [10.71573, 13.578422, 10.71573, 16.638063]\n",
    "#temp = [19.04899024963379, 1377.4075927734375, 19.04899024963379, 26.09033203125]\n",
    "#df_metrics_plot.loc[4] = temp\n",
    "\n",
    "df_metrics_plot['MSE'] = [ math.sqrt(x) for x in df_metrics_plot['MSE']];\n",
    "df_metrics_plot\n",
    "#df_metrics, df_metrics_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_plot.plot( kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the sake of easier execution, I have brought financial news based prediction in the same code file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Import Libraries\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "# Import Libraries for Graph, GNN, and GCN\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph import StellarGraph\n",
    "\n",
    "from stellargraph.mapper import FullBatchNodeGenerator\n",
    "from stellargraph.layer import GCN\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# Machine Learnig related library Imports\n",
    "\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
    "from sklearn import preprocessing, model_selection\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# was active\n",
    "\n",
    "data_folder = './data/yahoonewsarchive/'\n",
    "# os.chdir(data_folder);\n",
    "# file = data_folder + 'NEWS_YAHOO_stock_prediction.csv';\n",
    "file = data_folder + 'News_Yahoo_stock.csv';\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "df_news = pd.read_csv(file)\n",
    "df_news.head()\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "df_news = df_news[:100]\n",
    "\n",
    "\n",
    "# # Approaches: Find all stock tickers in an/all article/articles\n",
    "# \n",
    "# 1. Find code that does this: from internet or from previous work or from courses that you have taken online or in academia\n",
    "# 2. Iterative read the article and match with stock tickers, and find all tickers. Drawback: to which tickers to match or how will you know what is a ticker? Any two to four letters Uppercase, NASDAQ AAPL\n",
    "# 3. Load the article in database and then use SQL -> may not work that well unless you write some functions\n",
    "# 4. NLTK, remove stop words, find all tokens, then find All Uppercase words. create a list. attach article ids to the list. Then match with the list of tockers. find common tickers between them. then create tuples with two (indicating edge) (source target weight) \n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# import NLTK libraries\n",
    "# remove stop words using NLTK methods \n",
    "# remove all sorts of unnecessary words\n",
    "# find all tokens\n",
    "# Keep only All Uppercase words in a list : dictionary/map: dataframe will be ideal\n",
    "# create a list/dictionary/map: dataframe will be ideal. attach article ids to the list/dataframe data.\n",
    "# Create a list of all NasDAQ Tickers\n",
    "# Then match with the list of NASDAQ tockers. \n",
    "# find common tickers between them. \n",
    "# then create tuples with two (indicating edge) (source target weight)\n",
    "# increase weight for each article and pair when you see a match\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "# import NLTK libraries\n",
    "import nltk\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "# remove stop words using NLTK methods \n",
    "# remove all sorts of unnecessary words\n",
    "# find all tokens\n",
    "# Keep only All Uppercase words in a list : dictionary/map: dataframe will be ideal\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "dataFrameWithOnlyCapitalWords = pd.DataFrame(columns =  [\"id\", \"Title\", \"Content\"]) \n",
    "for index, row in df_news.iterrows():\n",
    "    # print(row[id], row['title'], row['content'])\n",
    "                \n",
    "    # words with capital letters in the beginning +  as much as possible\n",
    "    capitalWords = RegexpTokenizer('[A-Z]+[A-Z]\\w+')\n",
    "    # print(\"\\n::All Capital Words::\", capitalWords.tokenize(row['content']))\n",
    "    allCapitalWords = capitalWords.tokenize(row['content'])\n",
    "        \n",
    "    dataFrameWithOnlyCapitalWords.loc[index] = [index, row['title'], allCapitalWords]\n",
    "    #break\n",
    "\n",
    "\n",
    "\n",
    "dataFrameWithOnlyCapitalWords.head() #, dataFrameWithOnlyCapitalWords.shape\n",
    "\n",
    "\n",
    "# # Create a list of all (NasDAQ) 30 stocks as per the paper\n",
    "# \n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# Find/Create a list of NASDAQ Stocks\n",
    "import os\n",
    "import glob\n",
    "nasdaqDataFolder = './archive/stock_market_data/nasdaq/csv'\n",
    "os.chdir(nasdaqDataFolder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# Create a list of all NasDAQ Tickers\n",
    "\n",
    "extension = \"csv\"\n",
    "fileTypesToMerge = \"\"\n",
    "# all_filenames = [i for i in glob.glob('*' + '*.{}'.format(extension))]\n",
    "all_nasdaq_tickers = [i[:-4] for i in glob.glob('*' + fileTypesToMerge + '*.{}'.format(extension))]\n",
    "nasdaq_tickers_to_process = all_nasdaq_tickers #[:10]\n",
    "nasdaq_tickers_to_process\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "nasdaq_tickers_to_process.remove('FREE')\n",
    "nasdaq_tickers_to_process.remove('CBOE')\n",
    "nasdaq_tickers_to_process.remove('III')\n",
    "nasdaq_tickers_to_process.remove('RVNC')\n",
    "sorted(nasdaq_tickers_to_process)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "fortune_30_tickers_to_process = [\n",
    "'WMT',\n",
    "'XOM',\n",
    "'AAPL',\n",
    "'UNH',\n",
    "'MCK',\n",
    "'CVS',\n",
    "'AMZN',\n",
    "'T',\n",
    "'GM',\n",
    "'F',\n",
    "'ABC',\n",
    "'CVX',\n",
    "'CAH',\n",
    "'COST',\n",
    "'VZ',\n",
    "'KR',\n",
    "'GE',\n",
    "'WBA',\n",
    "'JPM',\n",
    "'GOOGL',\n",
    "'HD',\n",
    "'BAC',\n",
    "'WFC',\n",
    "'BA',\n",
    "'PSX',\n",
    "'ANTM',\n",
    "'MSFT',\n",
    "'UNP',\n",
    "'PCAR',\n",
    "'DWDP']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# nasdaq_tickers_to_process = [\n",
    "# 'WMT',\n",
    "# 'XOM',\n",
    "# 'AAPL',\n",
    "# 'UNH',\n",
    "# 'MCK',\n",
    "# 'CVS',\n",
    "# 'AMZN',\n",
    "# 'T',\n",
    "# 'GM',\n",
    "# 'F',\n",
    "# 'ABC',\n",
    "# 'CVX',\n",
    "# 'CAH',\n",
    "# 'COST',\n",
    "# 'VZ',\n",
    "# 'KR',\n",
    "# 'GE',\n",
    "# 'WBA',\n",
    "# # 'JPM',\n",
    "# #'GOOGL',\n",
    "# 'HD',\n",
    "# 'BAC',\n",
    "# 'WFC',\n",
    "# 'BA',\n",
    "# 'PSX',\n",
    "# 'ANTM',\n",
    "# 'MSFT',\n",
    "# 'UNP',\n",
    "# 'PCAR',\n",
    "# 'DWDP']\n",
    "# \n",
    "\n",
    "# # Find NASDQ Tickers in each article\n",
    "# Create graph steps\n",
    "# Find all edges \n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "combinedTupleList = [];\n",
    "allMatchingTickers = [];\n",
    "from itertools import combinations\n",
    "for index, row in dataFrameWithOnlyCapitalWords.iterrows():\n",
    "    #print(index)\n",
    "    #print(set(row['Content']))\n",
    "    #print(set(nasdaq_tickers_to_process));    \n",
    "    matchingTickers = set(set(fortune_30_tickers_to_process).intersection(set(row['Content'])))\n",
    "    #print(matchingTickers)\n",
    "    if len (matchingTickers) > 1:\n",
    "        allTuples = list(combinations(matchingTickers, 2));\n",
    "        #print(list(combinations(matchingTickers, 2)))\n",
    "        \n",
    "        #allMatchingTickers = set(allMatchingTickers).union(matchingTickers);\n",
    "        for aTuple in allTuples:\n",
    "            combinedTupleList.append(tuple(sorted(aTuple)));\n",
    "            allMatchingTickers.append(aTuple[0])\n",
    "            allMatchingTickers.append(aTuple[1])\n",
    "            \n",
    "        \n",
    "    # print(\"*******************\");\n",
    "    #break\n",
    "    \n",
    "#combinedTupleList = list(set(combinedTupleList))\n",
    "allMatchingTickers = set(allMatchingTickers)\n",
    "\n",
    "# list(set(combinedTupleList)), len(combinedTupleList), len(set(combinedTupleList)), allMatchingTickers, len(allMatchingTickers), len(set(allMatchingTickers))\n",
    "sorted(combinedTupleList), type(aTuple), type(sorted(aTuple)), allMatchingTickers\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "#combinedTupleList[:1], set(allMatchingTickers)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# calculate edge weights\n",
    "from collections import Counter\n",
    "\n",
    "tuplesWithCount = dict(Counter(combinedTupleList))\n",
    "tuplesWithCount\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "l = list(tuplesWithCount.keys())\n",
    "l\n",
    "\n",
    "#print(list(zip(*l))[0])\n",
    "#print(list(zip(*l))[1])\n",
    "\n",
    "source = list(zip(*l))[0];\n",
    "target = list(zip(*l))[1];\n",
    "edge_weights = tuplesWithCount.values()\n",
    "source, target, edge_weights, len(source), len(target)\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "Graph_news = nx.Graph(tuplesWithCount.keys())\n",
    "nx.draw_networkx(Graph_news, pos = nx.circular_layout(Graph_news), node_color = 'r', edge_color = 'b')\n",
    "#tuplesWithCount.keys()\n",
    "\n",
    "\n",
    "# # Finally Create graph based on financial news\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('../../../../')\n",
    "#os.chdir('./mcmaster/meng/747/project/')\n",
    "os.getcwd()\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "# Now create node data i.e time series to pass as part of the nodes\n",
    "'''\n",
    "df = pd.DataFrame();\n",
    "data_file = \"../../../..//archive/stock_market_data/nasdaq/nasdq-stock-price--all-merged.csv\"\n",
    "# stock-price--all-merged.csv\"\n",
    "df = pd.read_csv(data_file);\n",
    "df.head()\n",
    "'''\n",
    "\n",
    "# this is the place where the new dataset starts i.e. fortune 30 companies\n",
    "df = pd.DataFrame();\n",
    "data_file = \"per-day-fortune-30-company-stock-price-data.csv\";\n",
    "df = pd.read_csv(\"./data/\" + data_file, low_memory = False);\n",
    "df.head()\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "df.index\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "drop_cols_with_na = 1\n",
    "drop_rows_with_na = 0\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html\n",
    "\n",
    "\n",
    "try:\n",
    "  df = df.interpolate(inplace = False)\n",
    "except:\n",
    "  print(\"An exception occurred. Operation ignored\")\n",
    "  exit\n",
    "    \n",
    "df.isnull().values.any()\n",
    "df[df.isna().any(axis = 1)]  \n",
    "\n",
    "\n",
    "#----\n",
    "\n",
    "\n",
    "\n",
    "if drop_cols_with_na == 1:\n",
    "    df = df.dropna(axis = 1);    \n",
    "   \n",
    "df, df.shape\n",
    "\n",
    "## -- \n",
    "\n",
    "df.isnull().values.any()\n",
    "df[df.isna().any( axis = 1 )]\n",
    "\n",
    "\n",
    "## --\n",
    "\n",
    "# df_s_transpose.index = df_s_transpose['Date']\n",
    "#df.index = df.index.astype('datetime64[ns]')\n",
    "df\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "df_s =  df #[ ['Ticker', 'Date', 'Adjusted Close'] ];\n",
    "df_s\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "df_s[\"Date\"] = df_s[\"Date\"].astype('datetime64[ns]')\n",
    "df_s = df_s.sort_values( by = 'Date', ascending = True )\n",
    "df_s\n",
    "\n",
    "\n",
    "# df_s_pivot = df_s.pivot_table(index = 'Ticker', columns = 'Date', values = 'Adjusted Close')\n",
    "# df_s_pivot\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "allMatchingTickers\n",
    "\n",
    "\n",
    "# \n",
    "# \n",
    "# drop_rows_with_na = 0\n",
    "# if drop_rows_with_na == 1:\n",
    "#     df_s_transpose = df_s_transpose.dropna(axis=0);\n",
    "#     #df_s_transpose[\"Date\"] = df_s_transpose[\"Date\"].astype('datetime64[ns]')\n",
    "#     #df_s_transpose.sort_values(by='Date', ascending=False)\n",
    "#     df_s_transpose.to_csv('../../../..//archive/stock_market_data/nasdaq/-na-dropped-nasdq-stock-price--all-merged.csv');\n",
    "#    \n",
    "# df_s_transpose.head(100)\n",
    "# \n",
    "# \n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "df_s_transpose = df_s #_pivot.T\n",
    "df_s_transpose\n",
    "\n",
    "df_s_transpose_feature = df_s_transpose.reset_index(drop = True, inplace=False)\n",
    "# df_s_transpose_feature =  df_s_transpose_feature.values.tolist()\n",
    "# print(df_s_transpose_feature.values.tolist())\n",
    "#df_s_transpose_feature['AAPL'].values\n",
    "\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "df_s_transpose_feature = df_s_transpose.set_index('Date')\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "df_s_transpose_feature\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "#df_s_transpose['SIMO']\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "# df_s_transpose_feature['AAPL'].values\n",
    "len(allMatchingTickers), len(set(allMatchingTickers)) #, df_s['Ticker']\n",
    "#df_s_tickers = df_s['Ticker'];\n",
    "#len(df_s_tickers), len(set(allMatchingTickers)), df_s_transpose.columns.unique, len(set(df_s['Ticker']))\n",
    "#df_s_tickers = list(set(df_s['Ticker'])); # list(df_s_transpose.columns.unique) #\n",
    "#sorted(df_s_tickers)\n",
    "#for x in df_s_tickers:\n",
    " #   print(x)\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "df_s_tickers = df_s_transpose_feature.columns\n",
    "#df_s_tickers = list(set(df_s_tickers.drop('Date')))\n",
    "sorted(df_s_tickers[:5])\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "set_allMatchingTickers = set(allMatchingTickers)\n",
    "df_s_tickers = fortune_30_tickers_to_process #list(set(df_s['Ticker'])); # list(df_s_transpose.columns.unique) #\n",
    "node_Data_financial_news = [];\n",
    "\n",
    "'''\n",
    "for x in set_allMatchingTickers :\n",
    "    # if x in df_s_tickers:\n",
    "    print(x)\n",
    "    node_Data_financial_news.append( df_s_transpose_feature[x].values)\n",
    "'''  \n",
    "\n",
    "node_Data_financial_news = pd.DataFrame(df_s_transpose_feature) #, index = list(allMatchingTickers)) #, index = list(set_allMatchingTickers))\n",
    "#node_Data_financial_news = node_Data_financial_news.T \n",
    "node_Data_financial_news\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "node_Data_financial_news = node_Data_financial_news.T\n",
    "node_Data_financial_news\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "node_Data_financial_news\n",
    "\n",
    "\n",
    "# node_Data_financial_news#.drop(axis = 0)\n",
    "# node_Data_financial_news = node_Data_financial_news.T\n",
    "# node_Data_financial_news\n",
    "\n",
    "# node_Data_financial_news = node_Data_financial_news.drop('Date')\n",
    "# node_Data_financial_news\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "financial_news_edge_data = pd.DataFrame(\n",
    "    {\"source\": source, \"target\": target, \"edge_feature\": edge_weights}\n",
    ")\n",
    "\n",
    "financial_news_graph = StellarGraph(node_Data_financial_news, edges = financial_news_edge_data, node_type_default=\"corner\", edge_type_default=\"line\")\n",
    "print(financial_news_graph.info())\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# debug code\n",
    "# financial_news_graph_data,  sorted(node_Data_financial_news.columns.unique())\n",
    "# [1,2] + [2, 3,4], set(source + target).difference(sorted(node_Data_financial_news.columns.unique()))\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "# Generator\n",
    "generator = FullBatchNodeGenerator(financial_news_graph, method = \"gcn\")\n",
    "\n",
    "\n",
    "# # Machine Learning, Deep Learning, GCN, CNN\n",
    "\n",
    "# # Train Test Split\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "train_subjects, test_subjects = model_selection.train_test_split(\n",
    "    node_Data_financial_news #, train_size = 6, test_size = 4\n",
    ")\n",
    "# , train_size=6, test_size=None, stratify=pearson_graph_node_data\n",
    "\n",
    "val_subjects, test_subjects_step_2 = model_selection.train_test_split(\n",
    "    test_subjects #, test_size = 2\n",
    ")\n",
    "\n",
    "#, train_size = 500, test_size = None, stratify = test_subjects\n",
    "\n",
    "\n",
    "train_subjects.shape, test_subjects.shape, val_subjects.shape, test_subjects_step_2.shape\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "# just the target variables\n",
    "\n",
    "train_targets = train_subjects; \n",
    "val_targets = val_subjects; \n",
    "test_targets = test_subjects; \n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "# Architecture of the Neural Network\n",
    "train_subjects.index, train_targets\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "train_gen = generator.flow(train_subjects.index, train_targets)\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "'''\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "from tensorflow import keras\n",
    "\n",
    "layer_sizes = [32, 32]\n",
    "activations = [\"relu\", \"relu\"]\n",
    "'''\n",
    "\n",
    "gcn = GCN(layer_sizes = layer_sizes, activations = activations, generator = generator) #, dropout = 0.5\n",
    "x_inp, x_out = gcn.in_out_tensors()\n",
    "\n",
    "# MLP -- Regression\n",
    "predictions = layers.Dense(units = train_targets.shape[1], activation = \"linear\")(x_out)\n",
    "\n",
    "\n",
    "'''\n",
    "x_out, \n",
    "x_inp, x_out\n",
    "\n",
    "\n",
    "# # Models\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "# loss functions: https://keras.io/api/losses/\n",
    "\n",
    "model = Model(\n",
    "    inputs = x_inp, outputs = predictions)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.1),\n",
    "    loss=losses.MeanSquaredError(),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "\n",
    "# REF: https://stackoverflow.com/questions/57301698/how-to-change-a-learning-rate-for-adam-in-tf2\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay\n",
    "train_steps = 1000\n",
    "lr_fn = optimizers.schedules.PolynomialDecay(1e-3, train_steps, 1e-5, 2)\n",
    "\n",
    "\n",
    "# https://keras.io/api/metrics/\n",
    "model.compile(\n",
    "    loss = 'mean_absolute_error', \n",
    "    optimizer = optimizers.Adam( lr_fn ),\n",
    "    # metrics = ['mean_squared_error']\n",
    "    metrics=['mse', 'mae', 'mape']\n",
    ")\n",
    "'''\n",
    "# 4th block\n",
    "\n",
    "# mape: https://towardsdatascience.com/choosing-the-correct-error-metric-mape-vs-smape-5328dec53fac\n",
    "model.compile( \n",
    "    loss = 'mean_absolute_error', \n",
    "    optimizer = optimizers.Adam(learning_rate = 0.015), \n",
    "    #optimizer = optimizers.Adam(lr_fn), \n",
    "    # metrics=['mean_squared_error']\n",
    "    metrics=['mean_squared_error', 'mae', 'mape']\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "len(x_inp), predictions.shape, print(model.summary())\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "len(val_subjects)\n",
    "test_subjects_ = test_subjects[:len(val_subjects)]\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "# hard coded size adjustments\n",
    "test_subjects_ = test_subjects[:len(val_subjects)]\n",
    "\n",
    "val_gen = generator.flow(val_subjects.index, test_subjects_)\n",
    "#train_gen[1], val_gen[1]\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "\n",
    "data_valid = val_gen #[:1][:4];\n",
    "train_gen_data = train_gen #[:1][:4];\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "type(train_gen_data), type(data_valid), type(x_inp), type(x_out) \n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "'''\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es_callback = EarlyStopping(\n",
    "    monitor = \"val_mean_squared_error\", \n",
    "    patience = patience_to_test, \n",
    "    restore_best_weights = True\n",
    ")\n",
    "'''\n",
    "\n",
    "history = model.fit( train_gen_data, epochs = epochs_to_test, validation_data = data_valid, verbose = 2,    \n",
    "    # shuffling = true means shuffling the whole graph\n",
    "    shuffle = False, callbacks = [es_callback],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "val_subjects, \n",
    "test_subjects\n",
    "\n",
    "test_gen = generator.flow(test_subjects.index, test_targets)\n",
    "test_metrics = model.evaluate(test_gen)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "    \n",
    "\n",
    "\n",
    "# # Show the predicted prices by the Model\n",
    "# \n",
    "# At this point, I still need to make sense of what GCN ( and CNN) combination + MLP is predicting. \n",
    "# I am just displaying the output. \n",
    "# It appears that price is predicted for each timestamp (day)\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "all_nodes = node_Data_financial_news.index;\n",
    "all_gen = generator.flow(all_nodes)\n",
    "all_predictions = model.predict(all_gen)\n",
    "\n",
    "all_predictions, all_predictions.shape, node_Data_financial_news.shape\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_metrics = pd.DataFrame(columns=['Method', 'Loss', 'MSE', 'MAE', 'MAPE'])\n",
    "\n",
    "temp = list()\n",
    "temp.append('GCN-Causation-News');\n",
    "for name, val in zip(model.metrics_names, test_metrics):    \n",
    "    temp.append(val)\n",
    "\n",
    "print(temp)\n",
    "df_metrics.loc[1] = temp\n",
    "\n",
    "import math\n",
    "df_metrics_plot = df_metrics[['Loss', 'MSE', 'MAE', 'MAPE']]\n",
    "df_metrics_plot['MSE'] = math.sqrt(df_metrics['MSE'])\n",
    "df_metrics_plot\n",
    "\n",
    "\n",
    "df_metrics_plot.plot( kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_metrics = pd.DataFrame(columns=['Method', 'Loss', 'MSE', 'MAE', 'MAPE'])\n",
    "\n",
    "temp = list()\n",
    "temp.append('GCN-News');\n",
    "for name, val in zip(model.metrics_names, test_metrics):    \n",
    "    temp.append(val)\n",
    "\n",
    "df_metrics.loc[4] = temp\n",
    "\n",
    "# import math\n",
    "df_metrics_plot = df_metrics[['Loss', 'MSE', 'MAE', 'MAPE']]\n",
    "\n",
    "df_metrics_plot['MSE'] = [ math.sqrt(x) for x in df_metrics_plot['MSE']]\n",
    "df_metrics_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_plot.plot( kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, I have taken ideas from the following code esp. to see what GCN is and how GCN works.\n",
    "\n",
    "Although, it does not use any CNN. \n",
    "\n",
    "Node classification with Graph Convolutional Network (GCN). \n",
    "\n",
    "https://stellargraph.readthedocs.io/en/stable/demos/node-classification/gcn-node-classification.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7riPbvAKomIR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qw49sErnonN4"
   },
   "source": [
    "References:\n",
    "\n",
    "\n",
    "\n",
    "[1] Node classification with Graph Convolutional Network (GCN). https://stellargraph.readthedocs.io/en/stable/demos/node-classification/gcn-node-classification.html \n",
    "\n",
    "\n",
    "[2] Loading data into StellarGraph from Pandas. https://stellargraph.readthedocs.io/en/stable/demos/basics/loading-pandas.html\n",
    "\n",
    "[3] Load Timeseries https://stellargraph.readthedocs.io/en/stable/demos/basics/loading-numpy.html\n",
    "\n",
    "[4] NetworkX: https://networkx.org/documentation/stable/reference/introduction.html \n",
    "\n",
    "[5]  StellerGraph and Networkx https://stellargraph.readthedocs.io/en/latest/demos/basics/loading-networkx.html \n",
    "\n",
    "[6] Select StellerGraph Algorithm : https://stellargraph.readthedocs.io/en/stable/demos/#find-a-demo-for-an-algorithm \n",
    "[link text](https://)\n",
    "\n",
    "\n",
    "Learning: \n",
    "GNN/GCN/Keras\n",
    "https://www.youtube.com/watch?v=0KH95BEz370\n",
    "\n",
    "\n",
    "Install StellarGraph:\n",
    "https://pypi.org/project/stellargraph/#install-stellargraph-using-pypi\n",
    "\n",
    "\n",
    "May want to use without Stellar\n",
    "https://keras.io/examples/graph/gnn_citations/\n",
    "\n",
    "to get feature data from pandas dataframe: \n",
    "https://stellargraph.readthedocs.io/en/stable/demos/basics/loading-pandas.html\n",
    "\n",
    "\n",
    "Create graph properly:\n",
    "https://stellargraph.readthedocs.io/en/stable/demos/basics/loading-pandas.html    \n",
    "\n",
    "https://stellargraph.readthedocs.io/en/v0.11.0/api.html\n",
    "\n",
    "\n",
    "Graph Regression Dataset\n",
    "https://paperswithcode.com/task/graph-regression/codeless\n",
    "\n",
    "StellerGraph Reference:\n",
    "https://stellargraph.readthedocs.io/en/stable/demos/time-series/gcn-lstm-time-series.html\n",
    "https://stellargraph.readthedocs.io\n",
    "\n",
    "GRaph CNN or similar\n",
    "It has multiple GCN layers and one 1d CNN + ... this idea might help\n",
    "https://stellargraph.readthedocs.io/en/stable/demos/graph-classification/dgcnn-graph-classification.html?highlight=cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References -- exploring ideas on the GCN-CNN\n",
    "https://ieeexplore.ieee.org/document/9149910\n",
    "\n",
    "https://antonsruberts.github.io/graph/gcn/\n",
    "\n",
    "This may work. As Unit GCN is created also unit tcn. This may give the opportunity to customize to product the correct output\n",
    "https://github.com/lshiwjx/2s-AGCN  https://paperswithcode.com/paper/non-local-graph-convolutional-networks-for\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from scracth and equations\n",
    "https://towardsdatascience.com/understanding-graph-convolutional-networks-for-node-classification-a2bfdb7aba7b\n",
    "\n",
    "https://jonathan-hui.medium.com/graph-convolutional-networks-gcn-pooling-839184205692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPC55bf7KmvCURxoGTa/FB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
